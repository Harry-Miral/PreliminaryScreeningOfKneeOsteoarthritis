{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452b9946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T12:59:35.081622Z",
     "start_time": "2022-07-05T12:59:35.077621Z"
    }
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cf216bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:46.997604Z",
     "start_time": "2022-07-07T13:19:42.857680Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from pandas import read_csv, unique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import mode\n",
    "from scipy import interp\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow import stack\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, BatchNormalization, MaxPool1D, Reshape, Activation\n",
    "from keras.layers import Conv1D, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0860",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4351ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:47.013608Z",
     "start_time": "2022-07-07T13:19:46.998607Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    df = read_csv(filepath, header=None, names=['user-id',\n",
    "                                               'activity',\n",
    "                                               'timestamp',\n",
    "                                               'sex',\n",
    "                                               'age',\n",
    "                                               'BMI',\n",
    "                                               'A',\n",
    "                                               'B',\n",
    "                                               'C',\n",
    "                                               'X',\n",
    "                                               'Y',\n",
    "                                               'Z'])\n",
    "    ## removing ';' from last column and converting it to float\n",
    "    df['Z'].replace(regex=True, inplace=True, to_replace=r';', value=r'')\n",
    "    df['Z'] = df['Z'].apply(convert_to_float)\n",
    "#     df.dropna(axis=0, how='any', inplace=True)\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float64(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe14cbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:48.655211Z",
     "start_time": "2022-07-07T13:19:47.014608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.842623</td>\n",
       "      <td>170.059424</td>\n",
       "      <td>171.885206</td>\n",
       "      <td>164.917391</td>\n",
       "      <td>165.412991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.642798</td>\n",
       "      <td>170.228278</td>\n",
       "      <td>172.175605</td>\n",
       "      <td>164.844014</td>\n",
       "      <td>165.337399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.442973</td>\n",
       "      <td>170.397132</td>\n",
       "      <td>172.466004</td>\n",
       "      <td>164.770636</td>\n",
       "      <td>165.261807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.392961</td>\n",
       "      <td>170.137725</td>\n",
       "      <td>171.981197</td>\n",
       "      <td>164.342390</td>\n",
       "      <td>165.068027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.342949</td>\n",
       "      <td>169.878317</td>\n",
       "      <td>171.496389</td>\n",
       "      <td>163.914143</td>\n",
       "      <td>164.874246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>395.0</td>\n",
       "      <td>25.100288</td>\n",
       "      <td>175.285201</td>\n",
       "      <td>169.166791</td>\n",
       "      <td>167.176578</td>\n",
       "      <td>143.908137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>396.0</td>\n",
       "      <td>24.407383</td>\n",
       "      <td>175.156822</td>\n",
       "      <td>169.516578</td>\n",
       "      <td>166.584673</td>\n",
       "      <td>144.295324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>397.0</td>\n",
       "      <td>25.290760</td>\n",
       "      <td>174.922366</td>\n",
       "      <td>169.729140</td>\n",
       "      <td>167.409571</td>\n",
       "      <td>143.100077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>398.0</td>\n",
       "      <td>25.732448</td>\n",
       "      <td>174.805139</td>\n",
       "      <td>169.835422</td>\n",
       "      <td>167.822019</td>\n",
       "      <td>142.502453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>399.0</td>\n",
       "      <td>26.174136</td>\n",
       "      <td>174.687911</td>\n",
       "      <td>169.941703</td>\n",
       "      <td>168.234468</td>\n",
       "      <td>141.904830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp      A          B           C           X  \\\n",
       "0             1      Yes          0    0.0  23.842623  170.059424  171.885206   \n",
       "1             1      Yes          1    1.0  23.642798  170.228278  172.175605   \n",
       "2             1      Yes          2    2.0  23.442973  170.397132  172.466004   \n",
       "3             1      Yes          3    3.0  23.392961  170.137725  171.981197   \n",
       "4             1      Yes          4    4.0  23.342949  169.878317  171.496389   \n",
       "...         ...      ...        ...    ...        ...         ...         ...   \n",
       "142795      357      Yes        395  395.0  25.100288  175.285201  169.166791   \n",
       "142796      357      Yes        396  396.0  24.407383  175.156822  169.516578   \n",
       "142797      357      Yes        397  397.0  25.290760  174.922366  169.729140   \n",
       "142798      357      Yes        398  398.0  25.732448  174.805139  169.835422   \n",
       "142799      357      Yes        399  399.0  26.174136  174.687911  169.941703   \n",
       "\n",
       "                 Y           Z  \n",
       "0       164.917391  165.412991  \n",
       "1       164.844014  165.337399  \n",
       "2       164.770636  165.261807  \n",
       "3       164.342390  165.068027  \n",
       "4       163.914143  164.874246  \n",
       "...            ...         ...  \n",
       "142795  167.176578  143.908137  \n",
       "142796  166.584673  144.295324  \n",
       "142797  167.409571  143.100077  \n",
       "142798  167.822019  142.502453  \n",
       "142799  168.234468  141.904830  \n",
       "\n",
       "[142800 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data('Dataset/Angel_and_Baseline/Angel_data_Walk_order.txt')\n",
    "df = df.drop(labels=['sex', 'age','BMI'], axis=1) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfc0f2",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78699eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.436290Z",
     "start_time": "2022-07-07T13:19:50.281071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.842623</td>\n",
       "      <td>170.059424</td>\n",
       "      <td>171.885206</td>\n",
       "      <td>164.917391</td>\n",
       "      <td>165.412991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.642798</td>\n",
       "      <td>170.228278</td>\n",
       "      <td>172.175605</td>\n",
       "      <td>164.844014</td>\n",
       "      <td>165.337399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.442973</td>\n",
       "      <td>170.397132</td>\n",
       "      <td>172.466004</td>\n",
       "      <td>164.770636</td>\n",
       "      <td>165.261807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.392961</td>\n",
       "      <td>170.137725</td>\n",
       "      <td>171.981197</td>\n",
       "      <td>164.342390</td>\n",
       "      <td>165.068027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.342949</td>\n",
       "      <td>169.878317</td>\n",
       "      <td>171.496389</td>\n",
       "      <td>163.914143</td>\n",
       "      <td>164.874246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>395.0</td>\n",
       "      <td>25.100288</td>\n",
       "      <td>175.285201</td>\n",
       "      <td>169.166791</td>\n",
       "      <td>167.176578</td>\n",
       "      <td>143.908137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>396.0</td>\n",
       "      <td>24.407383</td>\n",
       "      <td>175.156822</td>\n",
       "      <td>169.516578</td>\n",
       "      <td>166.584673</td>\n",
       "      <td>144.295324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>397.0</td>\n",
       "      <td>25.290760</td>\n",
       "      <td>174.922366</td>\n",
       "      <td>169.729140</td>\n",
       "      <td>167.409571</td>\n",
       "      <td>143.100077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>398.0</td>\n",
       "      <td>25.732448</td>\n",
       "      <td>174.805139</td>\n",
       "      <td>169.835422</td>\n",
       "      <td>167.822019</td>\n",
       "      <td>142.502453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>399.0</td>\n",
       "      <td>26.174136</td>\n",
       "      <td>174.687911</td>\n",
       "      <td>169.941703</td>\n",
       "      <td>168.234468</td>\n",
       "      <td>141.904830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp      A          B           C           X  \\\n",
       "0             1      Yes          0    0.0  23.842623  170.059424  171.885206   \n",
       "1             1      Yes          1    1.0  23.642798  170.228278  172.175605   \n",
       "2             1      Yes          2    2.0  23.442973  170.397132  172.466004   \n",
       "3             1      Yes          3    3.0  23.392961  170.137725  171.981197   \n",
       "4             1      Yes          4    4.0  23.342949  169.878317  171.496389   \n",
       "...         ...      ...        ...    ...        ...         ...         ...   \n",
       "142795      357      Yes        395  395.0  25.100288  175.285201  169.166791   \n",
       "142796      357      Yes        396  396.0  24.407383  175.156822  169.516578   \n",
       "142797      357      Yes        397  397.0  25.290760  174.922366  169.729140   \n",
       "142798      357      Yes        398  398.0  25.732448  174.805139  169.835422   \n",
       "142799      357      Yes        399  399.0  26.174136  174.687911  169.941703   \n",
       "\n",
       "                 Y           Z  activityEncode  \n",
       "0       164.917391  165.412991               1  \n",
       "1       164.844014  165.337399               1  \n",
       "2       164.770636  165.261807               1  \n",
       "3       164.342390  165.068027               1  \n",
       "4       163.914143  164.874246               1  \n",
       "...            ...         ...             ...  \n",
       "142795  167.176578  143.908137               1  \n",
       "142796  166.584673  144.295324               1  \n",
       "142797  167.409571  143.100077               1  \n",
       "142798  167.822019  142.502453               1  \n",
       "142799  168.234468  141.904830               1  \n",
       "\n",
       "[142800 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode = LabelEncoder()\n",
    "df['activityEncode'] = label_encode.fit_transform(df['activity'].values.ravel())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be5152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T16:53:26.834976Z",
     "start_time": "2022-07-04T16:53:26.823973Z"
    }
   },
   "source": [
    "## Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7951cd31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.484301Z",
     "start_time": "2022-07-07T13:19:50.437290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6d9e58d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.532284Z",
     "start_time": "2022-07-07T13:19:50.485302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.interpolate._interpolate.interp1d at 0x22ca7e936a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation_fn = interp1d(df['activityEncode'] ,df['Z'], kind='linear')\n",
    "interpolation_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f8ea8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.548288Z",
     "start_time": "2022-07-07T13:19:50.534285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_list = df[df['Z'].isnull()].index.tolist()\n",
    "null_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f002bca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.580295Z",
     "start_time": "2022-07-07T13:19:50.549289Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in null_list:\n",
    "    y = df['activityEncode'][i]\n",
    "    value = interpolation_fn(y)\n",
    "    df['Z']=df['Z'].fillna(value)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4349e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.627795Z",
     "start_time": "2022-07-07T13:19:50.581295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abe57c",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a24a047f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263467</td>\n",
       "      <td>0.905807</td>\n",
       "      <td>0.915488</td>\n",
       "      <td>0.877280</td>\n",
       "      <td>0.871621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.259558</td>\n",
       "      <td>0.907417</td>\n",
       "      <td>0.918593</td>\n",
       "      <td>0.876677</td>\n",
       "      <td>0.870877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.255649</td>\n",
       "      <td>0.909026</td>\n",
       "      <td>0.921699</td>\n",
       "      <td>0.876075</td>\n",
       "      <td>0.870132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.254671</td>\n",
       "      <td>0.906553</td>\n",
       "      <td>0.916514</td>\n",
       "      <td>0.872557</td>\n",
       "      <td>0.868225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.253692</td>\n",
       "      <td>0.904080</td>\n",
       "      <td>0.911329</td>\n",
       "      <td>0.869040</td>\n",
       "      <td>0.866317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>0.955633</td>\n",
       "      <td>0.886416</td>\n",
       "      <td>0.895834</td>\n",
       "      <td>0.659933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.274514</td>\n",
       "      <td>0.954409</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.890972</td>\n",
       "      <td>0.663744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.291795</td>\n",
       "      <td>0.952173</td>\n",
       "      <td>0.892430</td>\n",
       "      <td>0.897747</td>\n",
       "      <td>0.651978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.300435</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.893567</td>\n",
       "      <td>0.901134</td>\n",
       "      <td>0.646095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309075</td>\n",
       "      <td>0.949938</td>\n",
       "      <td>0.894703</td>\n",
       "      <td>0.904522</td>\n",
       "      <td>0.640213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp         A         B         C         X  \\\n",
       "0             1      Yes          0  0.000000  0.263467  0.905807  0.915488   \n",
       "1             1      Yes          1  0.002506  0.259558  0.907417  0.918593   \n",
       "2             1      Yes          2  0.005013  0.255649  0.909026  0.921699   \n",
       "3             1      Yes          3  0.007519  0.254671  0.906553  0.916514   \n",
       "4             1      Yes          4  0.010025  0.253692  0.904080  0.911329   \n",
       "...         ...      ...        ...       ...       ...       ...       ...   \n",
       "142795      357      Yes        395  0.989975  0.288069  0.955633  0.886416   \n",
       "142796      357      Yes        396  0.992481  0.274514  0.954409  0.890157   \n",
       "142797      357      Yes        397  0.994987  0.291795  0.952173  0.892430   \n",
       "142798      357      Yes        398  0.997494  0.300435  0.951056  0.893567   \n",
       "142799      357      Yes        399  1.000000  0.309075  0.949938  0.894703   \n",
       "\n",
       "               Y         Z  activityEncode  \n",
       "0       0.877280  0.871621               1  \n",
       "1       0.876677  0.870877               1  \n",
       "2       0.876075  0.870132               1  \n",
       "3       0.872557  0.868225               1  \n",
       "4       0.869040  0.866317               1  \n",
       "...          ...       ...             ...  \n",
       "142795  0.895834  0.659933               1  \n",
       "142796  0.890972  0.663744               1  \n",
       "142797  0.897747  0.651978               1  \n",
       "142798  0.901134  0.646095               1  \n",
       "142799  0.904522  0.640213               1  \n",
       "\n",
       "[142800 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['age'] = (df['age']-df['age'].min())/(df['age'].max()-df['age'].min())\n",
    "#df['BMI'] = (df['BMI']-df['BMI'].min())/(df['BMI'].max()-df['BMI'].min())\n",
    "df['A'] = (df['A']-df['A'].min())/(df['A'].max()-df['A'].min())\n",
    "df['B'] = (df['B']-df['B'].min())/(df['B'].max()-df['B'].min())\n",
    "df['C'] = (df['C']-df['C'].min())/(df['C'].max()-df['C'].min())\n",
    "df['X'] = (df['X']-df['X'].min())/(df['X'].max()-df['X'].min())\n",
    "df['Y'] = (df['Y']-df['Y'].min())/(df['Y'].max()-df['Y'].min())\n",
    "df['Z'] = (df['Z']-df['Z'].min())/(df['Z'].max()-df['Z'].min())\n",
    "#df['sex'] = (df['sex']-df['sex'].min())/(df['sex'].max()-df['sex'].min())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a31ec3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments(df, time_steps, step, label_name):\n",
    "    N_FEATURES = 6\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['X'].values[i:i+time_steps]\n",
    "        ys = df['Y'].values[i:i+time_steps]\n",
    "        zs = df['Z'].values[i:i+time_steps]\n",
    "        aas = df['A'].values[i:i+time_steps]\n",
    "        bs = df['B'].values[i:i+time_steps]\n",
    "        cs = df['C'].values[i:i+time_steps]\n",
    "        #sexs = df['sex'].values[i:i+time_steps]\n",
    "        #ages = df['age'].values[i:i+time_steps]\n",
    "        #bmis = df['BMI'].values[i:i+time_steps]\n",
    "        label = mode(df[label_name][i:i+time_steps])[0][0]\n",
    "        segments.append([aas,bs,cs,xs, ys, zs])\n",
    "        labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype=np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "987cccea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263467</td>\n",
       "      <td>0.905807</td>\n",
       "      <td>0.915488</td>\n",
       "      <td>0.877280</td>\n",
       "      <td>0.871621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.259558</td>\n",
       "      <td>0.907417</td>\n",
       "      <td>0.918593</td>\n",
       "      <td>0.876677</td>\n",
       "      <td>0.870877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.255649</td>\n",
       "      <td>0.909026</td>\n",
       "      <td>0.921699</td>\n",
       "      <td>0.876075</td>\n",
       "      <td>0.870132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.254671</td>\n",
       "      <td>0.906553</td>\n",
       "      <td>0.916514</td>\n",
       "      <td>0.872557</td>\n",
       "      <td>0.868225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.253692</td>\n",
       "      <td>0.904080</td>\n",
       "      <td>0.911329</td>\n",
       "      <td>0.869040</td>\n",
       "      <td>0.866317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>0.955633</td>\n",
       "      <td>0.886416</td>\n",
       "      <td>0.895834</td>\n",
       "      <td>0.659933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.274514</td>\n",
       "      <td>0.954409</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.890972</td>\n",
       "      <td>0.663744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.291795</td>\n",
       "      <td>0.952173</td>\n",
       "      <td>0.892430</td>\n",
       "      <td>0.897747</td>\n",
       "      <td>0.651978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.300435</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.893567</td>\n",
       "      <td>0.901134</td>\n",
       "      <td>0.646095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309075</td>\n",
       "      <td>0.949938</td>\n",
       "      <td>0.894703</td>\n",
       "      <td>0.904522</td>\n",
       "      <td>0.640213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp         A         B         C         X  \\\n",
       "0             1      Yes          0  0.000000  0.263467  0.905807  0.915488   \n",
       "1             1      Yes          1  0.002506  0.259558  0.907417  0.918593   \n",
       "2             1      Yes          2  0.005013  0.255649  0.909026  0.921699   \n",
       "3             1      Yes          3  0.007519  0.254671  0.906553  0.916514   \n",
       "4             1      Yes          4  0.010025  0.253692  0.904080  0.911329   \n",
       "...         ...      ...        ...       ...       ...       ...       ...   \n",
       "142795      357      Yes        395  0.989975  0.288069  0.955633  0.886416   \n",
       "142796      357      Yes        396  0.992481  0.274514  0.954409  0.890157   \n",
       "142797      357      Yes        397  0.994987  0.291795  0.952173  0.892430   \n",
       "142798      357      Yes        398  0.997494  0.300435  0.951056  0.893567   \n",
       "142799      357      Yes        399  1.000000  0.309075  0.949938  0.894703   \n",
       "\n",
       "               Y         Z  activityEncode  \n",
       "0       0.877280  0.871621               1  \n",
       "1       0.876677  0.870877               1  \n",
       "2       0.876075  0.870132               1  \n",
       "3       0.872557  0.868225               1  \n",
       "4       0.869040  0.866317               1  \n",
       "...          ...       ...             ...  \n",
       "142795  0.895834  0.659933               1  \n",
       "142796  0.890972  0.663744               1  \n",
       "142797  0.897747  0.651978               1  \n",
       "142798  0.901134  0.646095               1  \n",
       "142799  0.904522  0.640213               1  \n",
       "\n",
       "[142800 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b783875",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PERIOD = 80\n",
    "STEP_DISTANCE = 40\n",
    "LABEL = 'activityEncode'\n",
    "\n",
    "df1=df[df['user-id']>70]\n",
    "df2=df[df['user-id']>140]\n",
    "df3=df[df['user-id']>210]\n",
    "df4=df[df['user-id']>280]\n",
    "\n",
    "a1=df.shape[0]\n",
    "b2=df1.shape[0]\n",
    "c3=df2.shape[0]\n",
    "d4=df3.shape[0]\n",
    "e5=df4.shape[0]\n",
    "\n",
    "df_test0 = df.iloc[0:a1-b2,:]\n",
    "df_train0 = df.iloc[a1-b2:a1,:]\n",
    "x_train0, y_train0 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test0, y_test0 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train0.shape[1], x_train0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train0 = x_train0.reshape(x_train0.shape[0], input_shape)\n",
    "x_train0 = x_train0.astype('float32')\n",
    "y_train0=np.asarray(y_train0).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test0.shape[1], x_test0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test0 = x_test0.reshape(x_test0.shape[0], input_shape)\n",
    "x_test0 = x_test0.astype('float32')\n",
    "y_test0=np.asarray(y_test0).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test1 = df.iloc[a1-b2:a1-c3,:]\n",
    "df_train1 = pd.concat([df_test0,df.iloc[a1-c3:a1,]])\n",
    "x_train1, y_train1 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test1, y_test1 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train1.shape[1], x_train1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train1 = x_train1.reshape(x_train1.shape[0], input_shape)\n",
    "x_train1 = x_train1.astype('float32')\n",
    "y_train1=np.asarray(y_train1).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test1.shape[1], x_test1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0], input_shape)\n",
    "x_test1 = x_test1.astype('float32')\n",
    "y_test1=np.asarray(y_test1).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test2 = df.iloc[a1-c3:a1-d4,:]\n",
    "df_train2 = pd.concat([df.iloc[0:a1-c3,:],df.iloc[a1-d4:a1,]])\n",
    "x_train2, y_train2 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test2, y_test2 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train2.shape[1], x_train2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train2 = x_train2.reshape(x_train2.shape[0], input_shape)\n",
    "x_train2 = x_train2.astype('float32')\n",
    "y_train2=np.asarray(y_train2).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test2.shape[1], x_test2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test2 = x_test2.reshape(x_test2.shape[0], input_shape)\n",
    "x_test2 = x_test2.astype('float32')\n",
    "y_test2=np.asarray(y_test2).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test3 = df.iloc[a1-d4:a1-e5,:]\n",
    "df_train3 = pd.concat([df.iloc[0:a1-d4,:],df.iloc[a1-e5:a1,]])\n",
    "x_train3, y_train3 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test3, y_test3 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train3.shape[1], x_train3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train3 = x_train3.reshape(x_train3.shape[0], input_shape)\n",
    "x_train3 = x_train3.astype('float32')\n",
    "y_train3=np.asarray(y_train3).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test3.shape[1], x_test3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test3 = x_test3.reshape(x_test3.shape[0], input_shape)\n",
    "x_test3 = x_test3.astype('float32')\n",
    "y_test3=np.asarray(y_test3).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test4 = df.iloc[a1-e5:a1,:]\n",
    "df_train4 = df.iloc[0:a1-e5,:]\n",
    "x_train4, y_train4 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test4, y_test4 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train4.shape[1], x_train4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train4 = x_train4.reshape(x_train4.shape[0], input_shape)\n",
    "x_train4 = x_train4.astype('float32')\n",
    "y_train4=np.asarray(y_train4).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test4.shape[1], x_test4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test4 = x_test4.reshape(x_test4.shape[0], input_shape)\n",
    "x_test4 = x_test4.astype('float32')\n",
    "y_test4=np.asarray(y_test4).astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40c9e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 480, 32)           4352      \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 480, 32)           8320      \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 1, 480, 32)        0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1, 240, 64)        4160      \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 240, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 60, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 59, 192)           24768     \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 59, 192)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 192)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 192)              768       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 193       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,561\n",
      "Trainable params: 42,177\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model.add(Reshape((1, 480, 32)))\n",
    "model.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model.add(Reshape((240, 64)))\n",
    "model.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model.add(Reshape((59, 192)))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(BatchNormalization(epsilon=1e-06))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1538a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.001\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 5.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "sgd = SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False)\n",
    "adam=optimizers.Adam(lr=0.00013, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "#lr_metric = get_lr_metric(adam)\n",
    "lr_metric = get_lr_metric(adam)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model1.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model1.add(Reshape((1, 480, 32)))\n",
    "model1.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model1.add(Reshape((240, 64)))\n",
    "model1.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model1.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model1.add(Reshape((59, 192)))\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(BatchNormalization(epsilon=1e-06))\n",
    "model1.add(Dense(1))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model2.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model2.add(Reshape((1, 480, 32)))\n",
    "model2.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model2.add(Reshape((240, 64)))\n",
    "model2.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model2.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model2.add(Reshape((59, 192)))\n",
    "model2.add(GlobalAveragePooling1D())\n",
    "model2.add(BatchNormalization(epsilon=1e-06))\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model3.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model3.add(Reshape((1, 480, 32)))\n",
    "model3.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model3.add(Reshape((240, 64)))\n",
    "model3.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model3.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model3.add(Reshape((59, 192)))\n",
    "model3.add(GlobalAveragePooling1D())\n",
    "model3.add(BatchNormalization(epsilon=1e-06))\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model4.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model4.add(Reshape((1, 480, 32)))\n",
    "model4.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model4.add(Reshape((240, 64)))\n",
    "model4.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model4.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model4.add(Reshape((59, 192)))\n",
    "model4.add(GlobalAveragePooling1D())\n",
    "model4.add(BatchNormalization(epsilon=1e-06))\n",
    "model4.add(Dense(1))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model5.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model5.add(Reshape((1, 480, 32)))\n",
    "model5.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model5.add(Reshape((240, 64)))\n",
    "model5.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model5.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model5.add(Reshape((59, 192)))\n",
    "model5.add(GlobalAveragePooling1D())\n",
    "model5.add(BatchNormalization(epsilon=1e-06))\n",
    "model5.add(Dense(1))\n",
    "model5.add(Activation('sigmoid'))\n",
    "model5.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2047136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 7s 188ms/step - loss: 0.6582 - accuracy: 0.5938 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 5s 187ms/step - loss: 0.6163 - accuracy: 0.6545 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 5s 187ms/step - loss: 0.5912 - accuracy: 0.7068 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 6s 199ms/step - loss: 0.5690 - accuracy: 0.7298 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.5508 - accuracy: 0.7643 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 6s 193ms/step - loss: 0.5267 - accuracy: 0.7849 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 6s 193ms/step - loss: 0.5025 - accuracy: 0.7939 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.4787 - accuracy: 0.8072 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 0.4632 - accuracy: 0.8145 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 6s 193ms/step - loss: 0.4432 - accuracy: 0.8176 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 6s 192ms/step - loss: 0.4265 - accuracy: 0.8236 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 0.4259 - accuracy: 0.8142 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 6s 193ms/step - loss: 0.4043 - accuracy: 0.8382 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 6s 192ms/step - loss: 0.3914 - accuracy: 0.8410 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 6s 193ms/step - loss: 0.3895 - accuracy: 0.8431 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.3854 - accuracy: 0.8424 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 6s 193ms/step - loss: 0.3782 - accuracy: 0.8473 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.3709 - accuracy: 0.8455 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 6s 199ms/step - loss: 0.3648 - accuracy: 0.8483 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3784 - accuracy: 0.8396 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3738 - accuracy: 0.8438 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 0.3714 - accuracy: 0.8431 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.3593 - accuracy: 0.8574 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.3642 - accuracy: 0.8490 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3600 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.3517 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.3572 - accuracy: 0.8522 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 7s 241ms/step - loss: 0.3562 - accuracy: 0.8490 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 7s 241ms/step - loss: 0.3616 - accuracy: 0.8487 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.3496 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3472 - accuracy: 0.8525 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3460 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3642 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.3565 - accuracy: 0.8556 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3462 - accuracy: 0.8598 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.3537 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 0.3525 - accuracy: 0.8529 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 7s 241ms/step - loss: 0.3448 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.3526 - accuracy: 0.8536 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.3530 - accuracy: 0.8553 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.3476 - accuracy: 0.8532 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3540 - accuracy: 0.8553 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3412 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3485 - accuracy: 0.8574 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3569 - accuracy: 0.8483 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 7s 241ms/step - loss: 0.3493 - accuracy: 0.8598 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3443 - accuracy: 0.8529 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.3470 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3439 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3423 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3400 - accuracy: 0.8647 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3460 - accuracy: 0.8567 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3409 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3416 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3445 - accuracy: 0.8679 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3392 - accuracy: 0.8553 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3362 - accuracy: 0.8619 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3335 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3335 - accuracy: 0.8668 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3360 - accuracy: 0.8640 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3445 - accuracy: 0.8574 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3347 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.3396 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.3367 - accuracy: 0.8644 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3451 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3366 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3423 - accuracy: 0.8556 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.3366 - accuracy: 0.8654 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3340 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 7s 234ms/step - loss: 0.3403 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3353 - accuracy: 0.8598 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3324 - accuracy: 0.8633 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.3257 - accuracy: 0.8672 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3426 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 7s 237ms/step - loss: 0.3368 - accuracy: 0.8633 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3285 - accuracy: 0.8713 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3352 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.3311 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 7s 237ms/step - loss: 0.3336 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 0.3357 - accuracy: 0.8598 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3252 - accuracy: 0.8665 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 0.3388 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3263 - accuracy: 0.8665 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3294 - accuracy: 0.8626 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3393 - accuracy: 0.8605 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3370 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 7s 237ms/step - loss: 0.3347 - accuracy: 0.8640 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3274 - accuracy: 0.8633 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 7s 237ms/step - loss: 0.3304 - accuracy: 0.8703 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3305 - accuracy: 0.8668 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.3280 - accuracy: 0.8665 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3299 - accuracy: 0.8672 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3238 - accuracy: 0.8668 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.3243 - accuracy: 0.8689 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3341 - accuracy: 0.8609 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3302 - accuracy: 0.8675 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3267 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 7s 234ms/step - loss: 0.3244 - accuracy: 0.8727 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.3269 - accuracy: 0.8685 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.3213 - accuracy: 0.8738 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 1.3009 - accuracy: 0.6862 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 38ms/step\n",
      "22/22 [==============================] - 1s 39ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 8s 220ms/step - loss: 0.6170 - accuracy: 0.6478 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.5387 - accuracy: 0.7437 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.5011 - accuracy: 0.7765 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.4642 - accuracy: 0.7999 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.4287 - accuracy: 0.8229 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.4254 - accuracy: 0.8061 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.4085 - accuracy: 0.8187 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.4015 - accuracy: 0.8326 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3937 - accuracy: 0.8347 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3802 - accuracy: 0.8445 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3799 - accuracy: 0.8431 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3875 - accuracy: 0.8285 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3697 - accuracy: 0.8389 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3847 - accuracy: 0.8382 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3722 - accuracy: 0.8473 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 6s 225ms/step - loss: 0.3659 - accuracy: 0.8494 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3672 - accuracy: 0.8431 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3643 - accuracy: 0.8476 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3792 - accuracy: 0.8386 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3724 - accuracy: 0.8455 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3611 - accuracy: 0.8497 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3598 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3590 - accuracy: 0.8536 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3583 - accuracy: 0.8522 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3629 - accuracy: 0.8504 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3520 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3556 - accuracy: 0.8525 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3539 - accuracy: 0.8459 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3578 - accuracy: 0.8459 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3522 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3589 - accuracy: 0.8515 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3543 - accuracy: 0.8494 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3509 - accuracy: 0.8487 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3552 - accuracy: 0.8522 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3509 - accuracy: 0.8504 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.3504 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3466 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3509 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 7s 223ms/step - loss: 0.3521 - accuracy: 0.8501 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3478 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3510 - accuracy: 0.8567 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3591 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3506 - accuracy: 0.8546 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.3441 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3425 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3484 - accuracy: 0.8529 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3498 - accuracy: 0.8581 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3532 - accuracy: 0.8637 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3486 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3393 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3447 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.3459 - accuracy: 0.8605 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.3414 - accuracy: 0.8567 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3385 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3436 - accuracy: 0.8584 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3410 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3380 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 7s 227ms/step - loss: 0.3372 - accuracy: 0.8672 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3432 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3423 - accuracy: 0.8525 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3399 - accuracy: 0.8581 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3389 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.3363 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3393 - accuracy: 0.8672 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3391 - accuracy: 0.8633 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.3390 - accuracy: 0.8637 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3421 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3399 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3306 - accuracy: 0.8675 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3370 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3422 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3341 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3377 - accuracy: 0.8640 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3335 - accuracy: 0.8626 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3255 - accuracy: 0.8651 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3314 - accuracy: 0.8584 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3337 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3367 - accuracy: 0.8581 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3340 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3332 - accuracy: 0.8609 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3250 - accuracy: 0.8682 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3379 - accuracy: 0.8584 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3341 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3387 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3284 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3301 - accuracy: 0.8651 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3304 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3361 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3393 - accuracy: 0.8626 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3381 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 7s 228ms/step - loss: 0.3290 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3237 - accuracy: 0.8679 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3306 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3293 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3242 - accuracy: 0.8668 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3242 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3287 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3317 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3242 - accuracy: 0.8626 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3266 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.3735 - accuracy: 0.8324 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 39ms/step\n",
      "22/22 [==============================] - 1s 38ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 8s 209ms/step - loss: 0.6280 - accuracy: 0.6510 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.5330 - accuracy: 0.7535 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.4848 - accuracy: 0.7824 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.4508 - accuracy: 0.7971 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.4282 - accuracy: 0.8110 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.4105 - accuracy: 0.8187 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.4113 - accuracy: 0.8149 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3957 - accuracy: 0.8274 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3832 - accuracy: 0.8372 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.4057 - accuracy: 0.8288 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3840 - accuracy: 0.8333 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3811 - accuracy: 0.8368 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3762 - accuracy: 0.8421 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 0.3680 - accuracy: 0.8434 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3672 - accuracy: 0.8434 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3681 - accuracy: 0.8361 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3715 - accuracy: 0.8365 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3629 - accuracy: 0.8452 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3740 - accuracy: 0.8421 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3629 - accuracy: 0.8462 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3659 - accuracy: 0.8445 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3636 - accuracy: 0.8490 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 7s 227ms/step - loss: 0.3596 - accuracy: 0.8494 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3660 - accuracy: 0.8476 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3632 - accuracy: 0.8455 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3563 - accuracy: 0.8532 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3521 - accuracy: 0.8476 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3575 - accuracy: 0.8487 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3656 - accuracy: 0.8431 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.3712 - accuracy: 0.8466 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3509 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3486 - accuracy: 0.8525 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3507 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3589 - accuracy: 0.8469 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3544 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3483 - accuracy: 0.8546 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3599 - accuracy: 0.8504 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.3612 - accuracy: 0.8424 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3539 - accuracy: 0.8525 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3462 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3515 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3446 - accuracy: 0.8574 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 7s 230ms/step - loss: 0.3483 - accuracy: 0.8504 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3548 - accuracy: 0.8553 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3525 - accuracy: 0.8532 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3522 - accuracy: 0.8469 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3489 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3489 - accuracy: 0.8511 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3505 - accuracy: 0.8539 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3581 - accuracy: 0.8522 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3519 - accuracy: 0.8483 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3567 - accuracy: 0.8550 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3505 - accuracy: 0.8532 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3491 - accuracy: 0.8581 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.3518 - accuracy: 0.8529 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3496 - accuracy: 0.8469 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3490 - accuracy: 0.8605 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3465 - accuracy: 0.8529 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3461 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3438 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3413 - accuracy: 0.8536 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3478 - accuracy: 0.8546 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.3489 - accuracy: 0.8553 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3446 - accuracy: 0.8581 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.3424 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3418 - accuracy: 0.8546 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3452 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3414 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3419 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3407 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3405 - accuracy: 0.8584 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3377 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.3373 - accuracy: 0.8633 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3464 - accuracy: 0.8483 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3469 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3363 - accuracy: 0.8574 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3408 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3368 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3377 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 7s 228ms/step - loss: 0.3373 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3453 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3376 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.3416 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3363 - accuracy: 0.8626 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3358 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3325 - accuracy: 0.8647 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3349 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3327 - accuracy: 0.8651 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3336 - accuracy: 0.8679 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3306 - accuracy: 0.8661 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3380 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3460 - accuracy: 0.8556 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3351 - accuracy: 0.8609 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3367 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3318 - accuracy: 0.8647 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3331 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3328 - accuracy: 0.8661 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.3295 - accuracy: 0.8665 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3342 - accuracy: 0.8633 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.3385 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.3934 - accuracy: 0.8195 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 39ms/step\n",
      "22/22 [==============================] - 1s 39ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 8s 209ms/step - loss: 0.6148 - accuracy: 0.6698 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.5427 - accuracy: 0.7455 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.5038 - accuracy: 0.7786 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.4684 - accuracy: 0.7929 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.4305 - accuracy: 0.8114 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.4153 - accuracy: 0.8183 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3966 - accuracy: 0.8312 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.4047 - accuracy: 0.8236 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3993 - accuracy: 0.8204 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3912 - accuracy: 0.8358 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3788 - accuracy: 0.8382 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3837 - accuracy: 0.8351 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3877 - accuracy: 0.8285 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3872 - accuracy: 0.8351 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3771 - accuracy: 0.8361 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.3855 - accuracy: 0.8347 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3798 - accuracy: 0.8375 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3764 - accuracy: 0.8438 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3690 - accuracy: 0.8452 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3661 - accuracy: 0.8466 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3791 - accuracy: 0.8396 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3736 - accuracy: 0.8445 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3692 - accuracy: 0.8441 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3659 - accuracy: 0.8452 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3622 - accuracy: 0.8480 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3655 - accuracy: 0.8424 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3614 - accuracy: 0.8494 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3704 - accuracy: 0.8448 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3628 - accuracy: 0.8487 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3668 - accuracy: 0.8476 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3632 - accuracy: 0.8466 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3616 - accuracy: 0.8462 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3631 - accuracy: 0.8508 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3543 - accuracy: 0.8567 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.3582 - accuracy: 0.8550 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3726 - accuracy: 0.8424 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3577 - accuracy: 0.8501 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3548 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3523 - accuracy: 0.8556 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3501 - accuracy: 0.8553 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3555 - accuracy: 0.8529 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3554 - accuracy: 0.8501 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3537 - accuracy: 0.8511 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3606 - accuracy: 0.8532 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3572 - accuracy: 0.8497 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3549 - accuracy: 0.8546 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.3519 - accuracy: 0.8529 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3559 - accuracy: 0.8522 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3657 - accuracy: 0.8452 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3521 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3495 - accuracy: 0.8536 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3640 - accuracy: 0.8459 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3647 - accuracy: 0.8487 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3599 - accuracy: 0.8532 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3516 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3499 - accuracy: 0.8584 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3523 - accuracy: 0.8511 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3481 - accuracy: 0.8574 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3485 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3475 - accuracy: 0.8619 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3481 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3503 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3549 - accuracy: 0.8522 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3464 - accuracy: 0.8504 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3493 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3521 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3522 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3486 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3491 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3476 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.3456 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 7s 229ms/step - loss: 0.3422 - accuracy: 0.8626 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 7s 231ms/step - loss: 0.3428 - accuracy: 0.8619 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 7s 237ms/step - loss: 0.3468 - accuracy: 0.8584 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 7s 228ms/step - loss: 0.3473 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3522 - accuracy: 0.8536 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 7s 230ms/step - loss: 0.3518 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3440 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3437 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3447 - accuracy: 0.8567 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.3415 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.3416 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3416 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3476 - accuracy: 0.8556 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3478 - accuracy: 0.8567 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3409 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3442 - accuracy: 0.8637 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3452 - accuracy: 0.8605 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.3444 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3442 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3471 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3433 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3443 - accuracy: 0.8640 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3406 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.3430 - accuracy: 0.8619 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3419 - accuracy: 0.8556 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3408 - accuracy: 0.8633 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3430 - accuracy: 0.8550 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3461 - accuracy: 0.8532 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3365 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.4144 - accuracy: 0.7966 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 41ms/step\n",
      "22/22 [==============================] - 1s 42ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 8s 209ms/step - loss: 0.6055 - accuracy: 0.6820 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.5313 - accuracy: 0.7622 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.4824 - accuracy: 0.7925 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.4514 - accuracy: 0.8033 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.4158 - accuracy: 0.8187 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.4048 - accuracy: 0.8246 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.4074 - accuracy: 0.8211 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3890 - accuracy: 0.8351 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3734 - accuracy: 0.8421 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3751 - accuracy: 0.8427 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.3652 - accuracy: 0.8448 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3580 - accuracy: 0.8434 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3628 - accuracy: 0.8483 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3657 - accuracy: 0.8452 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3622 - accuracy: 0.8417 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3502 - accuracy: 0.8508 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3563 - accuracy: 0.8497 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 5s 190ms/step - loss: 0.3610 - accuracy: 0.8452 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3457 - accuracy: 0.8511 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.3553 - accuracy: 0.8421 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3445 - accuracy: 0.8483 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3494 - accuracy: 0.8469 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3502 - accuracy: 0.8532 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3492 - accuracy: 0.8518 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3457 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3448 - accuracy: 0.8536 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3403 - accuracy: 0.8581 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3547 - accuracy: 0.8476 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3449 - accuracy: 0.8556 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3418 - accuracy: 0.8518 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3449 - accuracy: 0.8501 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3420 - accuracy: 0.8581 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3397 - accuracy: 0.8556 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.3422 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3355 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3439 - accuracy: 0.8522 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3455 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3400 - accuracy: 0.8605 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3363 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3393 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3402 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.3271 - accuracy: 0.8672 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3363 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3392 - accuracy: 0.8584 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3346 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3492 - accuracy: 0.8501 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3406 - accuracy: 0.8574 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3334 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3384 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3286 - accuracy: 0.8640 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3266 - accuracy: 0.8619 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3274 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3292 - accuracy: 0.8598 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3260 - accuracy: 0.8665 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3228 - accuracy: 0.8699 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3250 - accuracy: 0.8563 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3282 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3221 - accuracy: 0.8661 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3319 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3257 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3305 - accuracy: 0.8602 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3230 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3177 - accuracy: 0.8675 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3177 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3194 - accuracy: 0.8637 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3153 - accuracy: 0.8685 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3248 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3185 - accuracy: 0.8706 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3162 - accuracy: 0.8689 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3269 - accuracy: 0.8616 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3209 - accuracy: 0.8699 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3147 - accuracy: 0.8696 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3148 - accuracy: 0.8696 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3158 - accuracy: 0.8692 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.3192 - accuracy: 0.8696 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3266 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3126 - accuracy: 0.8748 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3095 - accuracy: 0.8706 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3138 - accuracy: 0.8741 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3094 - accuracy: 0.8689 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3084 - accuracy: 0.8710 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3176 - accuracy: 0.8654 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3030 - accuracy: 0.8794 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3046 - accuracy: 0.8696 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.3063 - accuracy: 0.8682 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3032 - accuracy: 0.8769 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.2977 - accuracy: 0.8685 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 0.3002 - accuracy: 0.8647 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.2991 - accuracy: 0.8734 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3003 - accuracy: 0.8689 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.2885 - accuracy: 0.8738 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3041 - accuracy: 0.8706 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.2939 - accuracy: 0.8738 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.2978 - accuracy: 0.8769 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.2943 - accuracy: 0.8797 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.2887 - accuracy: 0.8759 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.2928 - accuracy: 0.8745 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.2913 - accuracy: 0.8745 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.2899 - accuracy: 0.8839 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.2909 - accuracy: 0.8748 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.3267 - accuracy: 0.8510 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 40ms/step\n",
      "22/22 [==============================] - 1s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "tprs=[]\n",
    "mean_fpr=np.linspace(0,1,100)\n",
    "auck=[0,0,0,0,0]\n",
    "Recalls=[]\n",
    "F1score=[]\n",
    "specificity=[]\n",
    "accuracys = []\n",
    "for i in range(5):\n",
    "    if i==0:\n",
    "        x_train, y_train = x_train0,y_train0\n",
    "        x_test, y_test = x_test0,y_test0\n",
    "        model.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model.predict(x_test))\n",
    "        y_pred=model.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==1:\n",
    "        x_train, y_train = x_train1,y_train1\n",
    "        x_test, y_test = x_test1,y_test1\n",
    "        model2.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model2.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model2.predict(x_test))\n",
    "        y_pred=model2.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==2:\n",
    "        x_train, y_train = x_train2,y_train2\n",
    "        x_test, y_test = x_test2,y_test2\n",
    "        model3.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model3.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model3.predict(x_test))\n",
    "        y_pred=model3.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==3:\n",
    "        x_train, y_train = x_train3,y_train3\n",
    "        x_test, y_test = x_test3,y_test3\n",
    "        model4.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model4.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model4.predict(x_test))\n",
    "        y_pred=model4.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    else:\n",
    "        x_train, y_train = x_train4,y_train4\n",
    "        x_test, y_test = x_test4,y_test4\n",
    "        model5.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model5.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model5.predict(x_test))\n",
    "        y_pred=model5.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    auck[i] = auc(fpr, tpr)\n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "scores=np.array(scores)\n",
    "interval = stats.t.interval(0.95, scores.shape[0] - 1, scores.mean(), scores.std() / np.sqrt(scores.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc5b3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence interval：(0.7248618572751554, 0.8694074660738437)\n",
      "scores: 0.7971346616744995\n",
      "AUC: 0.9294250132485427\n"
     ]
    }
   ],
   "source": [
    "print(\"confidence interval：{}\".format(interval))\n",
    "print('scores:',np.mean(scores))\n",
    "print('AUC:',np.mean(auck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53c4f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalls: 0.9033613445378151\n",
      "F1score: 0.8588133168636066\n"
     ]
    }
   ],
   "source": [
    "print('Recalls:',np.mean(Recalls))\n",
    "print('F1score:',np.mean(F1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5af3fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9126212048121324, 0.9462288216849529)\n"
     ]
    }
   ],
   "source": [
    "conf = sms.DescrStatsW(auck).tconfint_mean(0.05)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b671583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22ca7ed3fd0>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAHECAYAAAC0iBrrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABU2UlEQVR4nO3deXhTVf4G8PcmbZKuQGmhBVrKKksFtGUXWQQUFHTGEQSHRWCAXx0QOjiyzAhFHVwRUQo4AhVFZFAYdUSgOuzgKFBmlEWUAgUsdKF0oWlLm/P745qkadOSpjf7+3mePiQ3N+m3hzRvz73nnCsJIQSIiIioTipXF0BEROQJGJhEREQ2YGASERHZgIFJRERkAwYmERGRDRiYRERENmBgEhER2YCBSUREZAOfD0whBAoLC8H1G4iIqC4+H5hFRUVo1KgRioqKGvQ6BoMBFy5cgMFgUKgy78B2sY7tYh3bxTq2i3XObhefD0wiIiJbMDCJiIhswMAkIiKyAQOTiIjIBgxMIiIiGzAwiYiIbMDAJCIisgEDk4iIyAYMTCIiIhswMImIiGzAwCQiIrIBA5OIiMgGbhWY+/fvx6hRo9CiRQtIkoR//vOft33Ovn37EB8fD51Oh7Zt22LNmjWOL5SIiHyOWwXmzZs30b17d7z99ts27X/+/HmMHDkSAwYMQHp6OhYuXIjZs2fjk08+cXClRETka/xcXUBVI0aMwIgRI2zef82aNYiJicGKFSsAAJ07d8bRo0fx2muv4dFHH3VQlURE5CwGg/xV9X5Zmfyl1wMXL/ohPBwIDnZ8LW4VmPV15MgRDB8+3GLb/fffj3Xr1uHWrVvw9/ev8ZyysjKUlZWZ7hcWFgKQr6vWkGuqGZ/P69VZYrtYx3axzl3bRQigvBwoLZU/qCsrbX+e8cO9tNT25xkMQHExUFAgf5WUCOTnB6FJEwFJsq9thAAqKsz1lJVJdr3O7b5Hebn5e9y6Zd/rGEOxtLSO1zBUApCgL2uCV14x4K677K0aUKlsO9jq0YF59epVNG/e3GJb8+bNUVFRgdzcXERFRdV4zrJly5CcnFxj+6VLlxASEmJ3LUII5OfnQ5IkSJLyb0RPxXaxju1ina3tIoQcPmVlEsrLJdO/5eVSnR/SQsj7mr9gel5pqYTCQhWKilQoLlahtNS8X3m56/+Pbt3yh79/2e139AGSwWBK0lsAMjML0LRpud2vFxsba9N+Hh2YAGr8UgkhrG43WrBgAZKSkkz3CwsLER0djejoaISGhtpdh8FggBAC0dHRNv+14gvYLtaxXawrKzMgL0/CrVutcOuWqsp2ICMD+Pln4OxZCXl5tvfWGkqtBgICnPO9aicACAQE6AC4Prxvx88P0Grlf+35e1Clkp+v08n/qtXmx6TKW9AaSqHTquDvb4C+8ia6do1ETIzjf488OjAjIyNx9epVi23Z2dnw8/ND06ZNrT5Hq9VCq9XW2K5SqRr8wWV8DX4AWmK7WOct7VJRAdy8aT4MV17lD30h5I6A8bHiYiAnB7h2DcjOBoqKzIc59XqgpESCXt8MAQHq2/a8Hdkx9/cHAgPlD2zjh7bxX2MQ2EKSAI3G/FwrZ4lqFRQENGokf+l0AllZ+WjRIgAqlf0/uL+/+WfRaBzThhqNZcApSq8H8vNNdw0BAcgsqEBMjHN+jzw6MPv27YvPP//cYtvu3buRkJBg9fwlEdVPaSlw7pzcu6sahDdvApmZ8tfVq3IwOotGA7RqZQ6zqkGm09Xdq5Ek6yFo3GYOKMcGcn0ZDIBWW4GYGLn35ZOqhSWCgoCQEPkkr5O4VWAWFxfj559/Nt0/f/48Tpw4gbCwMMTExGDBggW4cuUKNm7cCACYOXMm3n77bSQlJeEPf/gDjhw5gnXr1mHz5s2u+hGIPE55uRyIGRny55FxoMkvvwAXLzo2DP38LAMsJAQQogyxsTrodJIptCQJiI4GOnSQ/3VYD4bck7WwbNTIcvisE7hVYB49ehSDBw823Teea5w0aRJSU1ORlZWFzMxM0+Nt2rTBjh07MHfuXKxatQotWrTAypUrOaWEqA7l5cD33wPHjgEnT8qhaO/5QK1W7u2FhVke6quq6mHAgAAgIgJo1kz+Cgqy3NdgEMjMLEBMTCPf7UmRpbIy62HpAm4VmIMGDTIN2rEmNTW1xraBAwfi+PHjDqyKyHMIARQWms8RXrsm9xaN5xBv3JDDstyGAYUqFdC6tdyr69DB8jPKeFi0WTP3OnRJXkijkf/iKitzaVgCbhaYRGRJCLkH+MMP8h/Zxrlp1QfWFBWZA9KWMDSqeqizY0egeXP586hxY/lfDgUgl5Mk+RBGSUnNQxJOxsAkcjOlpcChQ8B//iMHZVGRsq/fpAmQkCB/de/u8s8gopqEsDx0IUlu8UZlYBK5UGWleZBNbi5w8KAclqWl9X8tjUbuITZrZvlv48aWI0qbNuVhVHJjer38V2LTpm43uouBSeREN27Ivcb//hf45psw3LhRd3IFBwNxccCddwIxMebQ8/e3nF4QGAiEhjIIycNVHQ2blweEh7vVPBoGJpEDCCH/3mdmytM1fvoJOHtWPs8oPy5Br/dDQEDNkAsKAgYMAIYMATp1YgiSj6g+dUSrdauwBBiYRIoQQl627dgxID1dHqhz82bdz1GpgHbt5GkWoaHyIJu2bYHevWtOzSDyarXNs3QzDEwiGxinaxhHoubkyIdXjecff/5Zvl8XrRZo317uNXbtKhASkoOOHaMbtNQZkcfzkLAEGJhEVgkBXL4sz1k0ftVnBa7wcHkOY0yM/NW+veUKNQYDkJnpxPXkiNyRB4UlwMAksiCEPCDnww+B06dtf55WK0/R6NlTnq4RHu64Gom8goeFJcDAJAIgT/Y/cQL4+GPrQRkYKE/sj4w0T9lo0sS8WHdIiNuNTyByb1UvXOoBYQkwMMlHCSFfZePECeDoUblXWVbt2rzR0cCwYfKUjrZtGYhEigoNNa/s7wFhCTAwyUdUVMhTPM6elRcc//57eZqXNdHRwPjxQP/+nNJB5FAeEpRGDEzyWkIAe/cCX34pX9OxrjVWGzeWzz326QP06sWgJFKcXi+PevPgOVMMTPJKRUXA228Dhw9bf1yrBbp0kVfRuftueT4kQ5LIQYwDfFQqeSF1Dw1NBiZ5FSGA48eBlSuB69fN26OizFfkuOMOeZqHH9/9RI5XdTSswSAvlMzAJHKN8nJ50M5338kDeHJyzI+FhACzZgF9+7quPiKfZW3qSGio6+ppIAYmeayrV4EdO4CvvrJ+Cay77gLmzJGPABGRk3ngPMvbYWCSxzl1Cti6VV63VVRbLMfPT54GMnCgvHg5z0sSuYAXhiXAwCQPcuoUsHmzPHeyKj8/4J575K/u3eXLXxGRi3hpWAIMTPIAp07JS9X997+W25s1A0aMkBcX8JLfRyLPVlnptWEJMDDJTRkMclB+9FHNoIyKAsaOBQYNcrsLshP5NrVantR844bXhSXAwCQ3YFymzniR5Z9+khcaqL5UHYOSyAMEBsrnSTx06khdGJjkVBUVchhmZspfFy7I962NcjWKigIef1weyMOgJHIzlZU1fzG9MCwBBiY50S+/AM89J1+A+XaaNZMXGejVC7j3XgYlkVvS6+XDr40bAwEBrq7G4RiY5BS5ucBf/wpkZ9d8rFEjORw7dDB/edmpDyLvU3U0bH6+fBjW39+1NTkYA5McrrhYwssvS6awjI4GHngAiImRv5o04XxJIo9ibeqIl4clwMAkB9PrgRUrGuPqVTkUIyOBF17g6jtEHsuL51neDgOTHKK8HNi1C9i6VcKVK/4ICJB7ks8/z7Ak8lg+HJYAA5MUJgSwc6c8f/L6dfPSdUFBwNKlcg+TiDyQj4clwMAkBQkBrF0LfPGF5fa77y7DrFk6xMTwRCWRR2JYAmBgkkIMBvkalF9/bd7Wty8wZoyAn18BWrXyvV8uIq+hUsmDEITw2bAEGJikgIoKYPly4MAB+b4kAXPnAoMHy0Gamena+oiogbRaefBBWZlHX8+yoRiY1CBFRcArr5ivIKJWA888A/Tv79KyiEhpWq385cMYmGS3jAzgxRfNixH4+wMLFgA9e7q2LiJqIL1ePnQUEuLqStwKA5PssmcP8Pbb8vQRQD6lMX8+EBfn2rqIqIGqD/BhaJowMKne0tLkAT5GHTvKPcvwcNfVREQKqB6WBoPranFDDEyqlxMngFWrzPfvvx+YMcMnVsUi8m6cOnJbDEyyWWYmsGyZfDUfABg9GvjDH1xbExEpgGFpE5WrCyDPcOMGkJwMlJTI93v3BqZOdWlJRKQEhqXNGJh0W4WFwOLF5tGw7doB8+bJc5mJyIMxLOuFh2SpTtevA3/5C3Dpknw/PFy+CLRO59q6iKiBhJD/GjZiWN4W+whUq5wceaqIMSzDwni1ESKvIUlA06byaiMMS5uwh0k1CAEcOwakpMihCQDNmsmLFPBqI0RexM8PiIjg+RUbMTDJwo8/AqmpwA8/mLe1bClf9JnzLIk8XHm5PAdMqnLlIIalzRiYBED+PVqzRl6UoKrOnYGFC4HGjV1SFhEpxTjAJyBA/oWWeLm9+mJgEvLz5cOtP/5o3taiBTBxItCvH3+viDxe1dGwer28iHpgoGtr8kAMTB+XkSEP5MnNle9rNMCUKfIKPn58dxB5PmtTRxiWduFHog/76Sd5DdiyMvl+eDjw178Cbdu6ti4iUgjnWSqKgenDUlPNYXnHHfK5Sk4ZIfISDEvFMTB91NmzwP/+J9+OigL+9jf5cCwReQGGpUNwPLGP2rrVfPvRRxmWRF6jtJRh6SAMTB906RLwzTfy7bAwYMgQ19ZDRArSaMzX22NYKoqHZH3QJ5+Ybz/yCK9lSeRVVCp5ybuSEiA42NXVeBX2MH1MTg6wd698OzgYeOABl5ZDRI6gUjEsHYCB6WO2bzdfAPqhh+RFP4jIg+n18kRqg8HVlXg9BqYPycoCdu2Sb2u1wKhRrq2HiBrIOBq2vBzIy5OvnEAOw8D0EUIAK1bIv1cAMHIkEBrq0pKIqCGqTx3RaLiOpYMxMH3EZ58Bp07JtyMjgfHjXVsPETUA51m6BAPTB/zyC7Bxo/n+008DOp3r6iGiBmBYuozbBWZKSgratGkDnU6H+Ph4HDhwoM79N23ahO7duyMwMBBRUVF48sknkZeX56Rq3Z/BYHkodtQoIC7OpSURkb0Yli7lVoG5ZcsWzJkzB4sWLUJ6ejoGDBiAESNGIDMz0+r+Bw8exMSJEzF16lScPHkSW7duxXfffYdp06Y5uXL3VFEBpKQAp0/L96Oi5Et2EZHnkbiCj8u5VWAuX74cU6dOxbRp09C5c2esWLEC0dHRWL16tdX9v/nmG8TGxmL27Nlo06YN7rnnHsyYMQNHjx51cuXuJy8PmD/fPCpWkoDZs3kolshTScYrJQAMSxdxm5V+ysvLcezYMcyfP99i+/Dhw3H48GGrz+nXrx8WLVqEHTt2YMSIEcjOzsbHH3+MBx98sNbvU1ZWhrIqb7zCwkIAgMFggKEB85iMz2/Iayjl1CngpZck3Lgh3/f3B/74R4EuXZw/Vcud2sWdsF2sY7tYZzAYUBESAoNWK1+oNiSE8y6h3PtFpbKt7+g2gZmbm4vKyko0b97cYnvz5s1x9epVq8/p168fNm3ahLFjx6K0tBQVFRUYPXo03nrrrVq/z7Jly5CcnFxj+6VLlxASEmJ3/UII5OfnQ5IkSC4c2l1YKGHBgnCUlso1hIdX4v/+rwCxsRWo5ci2Q7lLu7gbtot1bBfrarRLQYGrS3ILSr1fYmNjbdrPbQLTqPoPLYSotSFOnTqF2bNn47nnnsP999+PrKwsPPPMM5g5cybWrVtn9TkLFixAUlKS6X5hYSGio6MRHR2N0AZMTDQYDBBCIDo62ua/Vhzhk0/kNgwIAO68E3j2WYHQ0CCX1eMu7eJu2C7WsV2q0Ovlw0N+fmyXWji7XdwmMMPDw6FWq2v0JrOzs2v0Oo2WLVuG/v3745lnngEAdOvWDUFBQRgwYABeeOEFREVF1XiOVquFVqutsV2lUjW4wY2v4ao3tBBAWpp57vLs2UDjxq7/K93V7eKu2C7WsV0gh2VBAaBWywupV2kTn24XK5zZLm7T8hqNBvHx8UhLS7PYnpaWhn79+ll9TklJSY1GUqvVAOSeqa/53//k5e8AoEcPeVQsEXmYqlNHKivl++QW3CYwASApKQnvvvsu1q9fj9OnT2Pu3LnIzMzEzJkzAciHUydWmRcxatQobNu2DatXr0ZGRgYOHTqE2bNno1evXmjRooWrfgyX2bnTfPv++11XBxHZydo8ywaMrSBluc0hWQAYO3Ys8vLysHTpUmRlZSEuLg47duxA69atAQBZWVkWczInT56MoqIivP322/jTn/6Exo0bY8iQIXj55Zdd9SO4zI0bwJEj8u1GjYA+fVxaDhHVFxclcHtuFZgAkJiYiMTERKuPpaam1tg2a9YszJo1y8FVub+vvjJftmvYMHnkORF5CIalR3CrQ7JkHyHMCxQAwPDhrquFiOqJYekxGJhe4L//BYyDiznYh8iDVFQwLD0IA9ML7N5tvs3BPkQexLhqD8Cw9AA80+XhSkuB//xHvh0SwsE+RB4nJEReoIALPbs99jA93DffmC/d1b8/B/sQuT1r654yLD0CA9PD7d9vvj1woOvqICIb6PXAtWtA1SuPkMdgYHqwoiLg+HH5dtOmQNeurq2HiOpgHA0rBHD9ujzghzwKA9ODHTpknnt5773mNWSJyM1UnzoSGMjzJx6IgenBqh6Ovfde19VBRHXgPEuvwcD0UHl5wA8/yLdbtADatXNtPURkBcPSqzAwPdSBA/KpEICHY4ncEsPS6zAwPRRHxxK5MYalV2JgeqArV4CffpJvt20LtGrl2nqIqA4MS6/BYVoe6OuvzbcHDXJZGURUm4AA+d/ycoalF2FgehiDwRyYKhUweLBr6yGiWgQEmIOTvAIPyXqY9HR5zjMA9OwJNG7s0nKICJDPWd686eoqyMHYw/QwaWnm28OGua4OIvqVtQE+5JXYw/QghYXmK5M0agTEx7u2HiKfVz0sudydV2NgepB9+8y/j0OGcGUtIpfi1BGf0+DALCsrw5UrV1BuvMYUOYQQlheK5uFYIhdiWPokuwPz+PHjGDJkCEJCQhATE4ODBw8CALKzs3Hffffhq6++UqxIAjIygAsX5Nt33AFER7u0HCLfxbD0WXYF5okTJzBgwACcO3cOEydOtHisWbNm0Ov1eO+99xQpkGRV514OHeq6Ooh8GsPSp9kVmM899xxatmyJkydP4qWXXoIwLmr6q/vuuw/ffvutIgWSfDj2yBH5tr8/MGCAa+sh8kkGA1BQYL7PsPQ5dgXmgQMHMG3aNAQHB0Oysup3TEwMfvnllwYXR7KLF4HcXPl2t24ctU7kEiqVfKV2lYph6aPsGmdZWlqKRnW8WQoLC+0uiGo6etR8m1NJiFzI3x+IiADUaldXQi5gVw+zXbt2OHbsWK2Pf/311+jSpYvdRZGlqoGZkOC6Ooh8jrXR/wxLn2VXYI4fPx7vv/8+0qosO2M8NPvKK69g165dmDBhgjIV+rjiYuD0afl2y5ZAVJRr6yHyGXq9fC6k6nlL8ml2HZKdN28e0tLS8MADD6BDhw6QJAmzZ89GTk4OcnJyMGzYMCQmJipdq086cUIeawCwd0nkNFVHw968CWg0XEid7OthajQapKWl4dVXX0VwcDB0Oh3OnTuHyMhIvPLKK/jXv/4FlYqLCCmBh2OJnMza1BGGJaEBi6/7+fkhKSkJSUlJStZDVQhhDkydDuja1bX1EHk9zrOkOtjVDZwyZQr+Y1wF3Ipvv/0WU6ZMsbsokv38s/n0Sffu8gA9InIQhiXdhl2BmZqainPnztX6+Pnz57nSjwKqDkTm4VgiB2JYkg0ccqKxsLAQGo3GES/tU777znybgUnkIKWlDEuyic3nMP/3v//hxIkTpvsHDhxAhZVrv+Xn5yMlJQWdOnVSpEBfVVAA/PSTfDs2FggPd2k5RN7L31++Vl5FBcOS6mRzYG7fvh3JyckA5DmXa9euxdq1a63uGxwcjM2bNytToY86dEge9AOwd0nkUGq1vORdSQkQEuLqasiN2RyYkydPxqBBgyCEwJAhQ7Bo0SIMrXbZDEmSEBwcjC5dukCn0ylerC+penW0e+91XR1EPkGtZljSbdkcmK1bt0br1q0BAIsXL8ajjz6KuLg4hxXmyy5cMB+Obd8eaNPGpeUQeRe9Xu5NhoUBVi4eQVQbu+ZhLl68WOk6qIqqvUte+5JIQVVHw16/ztCkerF74QIAuHbtGo4ePYr8/HwYjOu3VVH94tJ0exUVwJ498m1/fx6OJVJM9akjfn4MS6oXuwLTYDDgqaeewrvvvms1KI0YmPX37beA8epoffvytAqRIjjPkhRg1zzM1157DWvXrsW4cePw3nvvQQiBl156CatWrUKHDh2QkJBgcSUTsh0PxxIpjGFJCrErMN977z3cf//92LhxI0aMGAEAiI+Px8yZM3Hs2DHk5ubWeb1Msu76dfPaseHh8nJ4RNQADEtSkF2BmZGRYQpK41VJbt26BQAICgrCk08+iXfffVehEn3Hv/9tnns5dCjAC74QNQDDkhRm10dyQECAaem74OBgSJKE7Oxs0+ORkZG4dOmSMhX6kAMHzLfvu891dRB5hZIS822GJSnArsBs3bo1zp8/DwDw9/dH+/btsXPnTtPjX331FZo3b65MhT7i5k3g1yZF27ZAZKRr6yHyeGFhgFbLsCTF2BWYQ4YMwbZt20z3J0yYgM2bN2Pw4MEYNGgQtm7dijFjxihWpC84dcp8OJbXvSRSgCTJocmwJIXYNa1k3rx5GD58OMrKyqDVarFgwQJcu3YNmzZtglqtxvTp07FkyRKFS/Vup06ZbzMwiexQWipPXlarzds4z5IUZFdgRkVFISoqynRfrVbjrbfewltvvaVYYb7mhx/MtxmYRPVkHODj5ycvpF41NIkU4pBxmMXFxXj++ecd8dJeqawM+Pln+XbLlkDjxi4th8izVB0NW1FhOdiHSEGKBubNmzexbNkyxMbG8pBsPfz4o/x7DrB3SVQv1qaOcHkscpB6BeZHH32E7t27IzAwENHR0ViwYIFpabx3330Xbdu2xaJFixAaGorVq1c7pGBvdPKk+TYvAENkI86zJCez+Rzm559/jvHjxwMAwsPDkZWVhVdeeQUGgwElJSVYtWoV2rdvj5dffhkTJkyAmucQbFY1MNnDJLIBw5JcwObAfPPNN9GsWTOkpaXhzjvvxPXr1/Hoo4/irbfewq1bt/Dyyy9j7ty58PNr0AVQfE5FBXDmjHw7PByIiHBtPURuj2FJLmLzIdn09HTMmDEDd955JwAgLCwML7zwAkpLSzF37lw888wzDEs7nDsnD/oB5N4lR8ET1aG8nGFJLmNzYN64cQPt2rWz2Na+fXsAwL28aKPdeP6SqB40GjkkAYYlOZ3NXUIhRI0epPF+YGCgslX5EM6/JKqnRo3k4AwIcHUl5GPqdQw1IyMD3377rel+QUEBAODMmTMIDg6usX+vXr0aWJ53E8K8wk9oKNCqlWvrIXJLQtQ8V8GwJBeoV2AuXrwYixcvrrF91qxZVvevrKy0ryofcfGivOg6AHTpwvOXRDXo9UBBgbx6j7+/q6shH2dzYFoLSmqY77833+bhWKJqqo6GzcuTh5Bzuhq5kNsFZkpKCl599VVkZWWha9euWLFiBQYMGFDr/mVlZVi6dCk++OADXL16Fa1atcKiRYswZcoUp9TbEFUDs1s319VB5HaMPUujgACGJbmcW80D2bJlC+bMmYOUlBT0798fa9euxYgRI3Dq1CnExMRYfc6YMWNw7do1rFu3Du3bt0d2djYqjOvMuTEhzAN+goOBNm1cWw+Ru5BKS+WeperXQfwcDUtuwq0Cc/ny5Zg6dSqmTZsGAFixYgV27dqF1atXY9myZTX237lzJ/bt24eMjAyEhYUBAGJjY51Zst0uXACKiuTbnH9J9Cu9HqqCAvmvSIBhSW7FbQKzvLwcx44dw/z58y22Dx8+HIcPH7b6nM8++wwJCQl45ZVX8P777yMoKAijR4/G888/j4BaRtGVlZWhzLhSAIDCwkIAgMFgMK2Law/j8219jRMnACHklIyLE2jAt3Zr9W0XX8F2sUKvhyEvz9wuxoXU2UZ8v9RCqXZRqWxbksBtAjM3NxeVlZVo3ry5xfbmzZvj6tWrVp+TkZGBgwcPQqfTYfv27cjNzUViYiKuX7+O9evXW33OsmXLkJycXGP7pUuXENKAqxwIIZCfnw9JkiDZ0F08eLAR9HotACA8/DoyM93/MLI96tsuvoLtYkkqLYWqoABCCBQUFEAEBspBWfU8pg/j+8U6pdrF1iOTbhOYRtV/aCFErQ1hMBggSRI2bdqERr8etlm+fDl+97vfYdWqVVZ7mQsWLEBSUpLpfmFhIaKjoxEdHY3Q0FC76zYYDBBCIDo6+rZ/rRgMwOXLEgIC5D+g+/Zt4bWHZOvTLr6E7VLNzZtAcDAMBgMqAwLQqmtXtksVfL9Y5+x2cZvADA8Ph1qtrtGbzM7OrtHrNIqKikLLli1NYQkAnTt3hhACly9fRocOHWo8R6vVQqvV1tiuUqka3ODG17jd62RkyNe4lSR5dKxa7aVp+Stb28XXsF2qCAmRB/mUl0MyGNguVvD9Yp0z28VtWl6j0SA+Ph5paWkW29PS0tCvXz+rz+nfvz9++eUXFBcXm7adPXsWKpUKrdx42RxOJyGyggN8yM3ZHZiXLl3ClClT0KpVK2g0Gvz73/8GAOTk5GDKlCn47rvv6v2aSUlJePfdd7F+/XqcPn0ac+fORWZmJmbOnAlAPpw6ceJE0/7jx49H06ZN8eSTT+LUqVPYv38/nnnmGUyZMqXWQT/uoGpg/nrxFyLfotcDpaWuroKoXuw6JHv+/Hn06dMHpaWl6NOnD7KyskyPRURE4OjRo3j33XfRs2fPer3u2LFjkZeXh6VLlyIrKwtxcXHYsWMHWrduDQDIyspCZmamaf/g4GCkpaVh1qxZSEhIQNOmTTFmzBi88MIL9vxYTlFZaZ5/2agREB3t2nqInK7qCj5hYYBO59p6iGxkV2AuWrQIarUaP/zwAwICAtCsWTOLx0eOHInPP//croISExORmJho9bHU1NQa2zp16lTjMK47O3dO/rwA5N6ltw72IbKq+sWfy8oYmOQx7Dok+9VXX+H//u//EB0dbXUEa+vWrXH58uUGF+eN/vc/822evySfUj0sec6SPIxdgVlYWIioqKhaHy8vL/eI5elcoer1LxmY5DMYluQF7ArM6OhonDx5stbHjxw5gvbt29tdlLcSAjhzRr7duDHQooVLyyFyDoYleQm7AvO3v/0t1q9fjx+qdJeMh2a3bNmCjz/+GGPGjFGmQi+Sl2e+/mW7djx/ST6AYUlexK7AXLRoEVq1aoXevXtj3LhxkCQJL774Inr27Inx48eje/fu+NOf/qR0rR7vwgXzbQ9ZI57IfgYDcOOG+T7DkjycXYEZGhqKI0eOYOrUqUhPT4cQAv/+979x7tw5JCYmYs+ePdBx5FsNVQPz15kyRN5LpZKnjUgSw5K8gt1L44WGhmLlypVYuXIlcnJyIIRAREQEFwauw8WL5tvsYZJP0GqBiAjAz21W4SSym109zOPHj1vcj4iIQLNmzRiWt2HsYapUgBuv3EdkP2uj4xmW5CXsCsyEhAR069YNr7/+eq2X3iJLFRWAcWpqq1aAv79r6yFSnF4PZGebr4xO5GXsHvRTXFyMZ555BtHR0XjwwQexZcsWiwszk6UrV8x/fPNwLHmdqqNhi4rkFXyIvIxdgfn8888jIyMDe/bswcSJE3Ho0CGMGzcOkZGRmDFjBg4dOqR0nR6v6vlLDvghr2Jt6oiVS+gReboGXd5r4MCBWLduHa5evYpNmzahT58+WL9+Pe69916r16L0ZVVHyLZp47IyiJTFeZbkQxS5HqZOp8O4cePw5ZdfIjU1FSEhIcjIyFDipb0Gp5SQ12FYko9RZPjamTNnsHHjRmzatAmXL1+GWq3GQw89pMRLew1jYAYGyqPsiTwaw5J8kN2BmZeXh82bN2Pjxo04duwYhBDo3r075s6diyeeeAIRTAWTmzeBnBz5duvWXBKPPBzDknyUXYH5yCOPYOfOnSgvL0fz5s0xZ84cTJo0Cd14+Q2rqlzzmiNkyfP5+8uTiQ0GhiX5FLsCc9euXXj44YcxadIk3H///VCr1UrX5VXOnzffZmCSx/PzA8LDgZISIDTU1dUQOY1dgXn16lU04l+VNuOUEvI6fn4MS/I5do2SZVjWD0fIkkerfs6SyEfZ1MNcunQpJEnCokWLoFKpsHTp0ts+R5Ik/PWvf21wgZ5OCHMPMzwcCA52bT1E9VI9LJs0cV0tRC5mU2AuWbIEkiTh2WefhUajwZIlS277HAamLDfXfNFonr8kj1I9LFWKTNsm8lg2Beb5X0etaDQai/t0e7xoNHkkTh0hqsGmwGxd7cRb9ftUu19+Md+OiXFdHUQ2Y1gSWWXXMZYhQ4bg66+/rvXxPXv2YMiQIXYX5U1yc823uZYDuT2GJVGt7ArMvXv34tq1a7U+np2djX379tldlDfJyzPfbtrUdXUQ3RbDkqhODjmLn5OTA51O54iX9jhVe5gMTHJrxcXm2wxLohpsXrhg//792Lt3r+n+tm3b8PPPP9fYLz8/Hx999BG6d++uSIGeztjDDAkBfh0zReSemjaV37AaDcOSyAqbA3PPnj1ITk4GIE8Z2bZtG7Zt22Z133bt2uGNN95QpkIPJgRw/bp8OzzctbUQ3ZZKJb9ReXUAIqtsDsw5c+Zg8uTJEEKgbdu2WLFiBR5++GGLfSRJQnBwMMLCwhQv1BMVFgIVFfJtHo4lt1NaKvcmq86vZFgS1crmwGzUqJFpSbwNGzZg4MCBnF5yG1XPX7KHSW7FOMBHowHCwrgoAZEN7Fp8fdKkSUrX4ZU4QpbcUtXRsOXl8lVHuGYj0W3ZFJgbN24EAEyYMAGSJJnu387EiRPtr8wLcIQsuR1rU0cYlkQ2sSkwJ0+eDEmS8Pjjj0Oj0ZjuCyFqfY4kST4fmOxhklvhPEuiBrEpMPfs2QPAvJas8T7VjYFJboNhSdRgNgXmwIED67xP1lUNTA76IZdhWBIpQtGhcRUVFcjnhWZNjOcwtVogMNC1tZCPKitjWBIpxK7A/Oyzz7BgwQKLbcuXL0dwcDDCw8Px8MMPo6ysTJECPZmxh8m54OQyGg1gXKaSYUnUIHYF5muvvYbMzEzT/ZMnT+LPf/4zOnXqhN/85jf4/PPPsXLlSsWK9EQlJfKRMIDnL8mFJAlo0gRo3JhhSdRAdgXmmTNncPfdd5vu/+Mf/0BQUBAOHjyIjz/+GL///e/xwQcfKFakJ+KAH3KZ6qPXJYnnBIgUYFdgFhQUoGmVFPjqq69w3333IfjX+VwDBgzAxYsXlanQQzEwySX0eiA727wmIxEpxq7AbNasmSkQCwsLcfToUdxzzz2mx8vKylBZWalMhR6KI2TJ6YyjYSsr5TegweDqioi8il1L4/Xt2xdr1qxBXFwcduzYgYqKCowcOdL0+Llz59CiRQvFivREXOWHnKr61BGdjuvDEinMrsBcsmQJBg8ejMceewwAMGXKFHTq1AkAIITA9u3bMWTIEOWq9EA8JEtOw3mWRE5hV2B26dIFp0+fxqFDh9C4cWMMGDDA9NiNGzcwd+5cDBo0SKkaPRJ7mOQUDEsip7ErMAEgLCwMo0aNqrG9SZMmePrppxtUlDcw9jDVanlEP5HiGJZETmV3YALA5cuX8dlnnyEjIwMA0K5dO4waNQqtWrVSpDhPZgzMJk14KokcgGFJ5HR2B+ZLL72ExYsXo6KiwuKqJXPmzMHSpUvx7LPPKlKgJ7p1CygokG9zhCw5RNVpIwxLIqewq+/z0UcfYeHChejcuTPee+89pKen4/jx49i4cSO6dOmChQsXYsuWLUrX6jGq/uHP85fkECEh8hfDkshp7OphvvHGG+jRowcOHz4MnXGdSgA9evTAY489hj59+uCNN97A2LFjFSvUk3DADzlFSIirKyDyKXb1ME+ePInf//73FmFppNVqMWHCBPzwww8NLs5TcdECUpxeD5SXu7oKIp9mV2CqVCqU1/HLe+vWLUg+fHkO9jBJUcYBPnl5DE0iF7IrMLt3747U1FQUFxfXeKyoqAgbNmzAXXfd1eDiPBUXLSDFVB0NKwRQWuraeoh8mF3nMP/85z/j4YcfRo8ePTBr1ix06dIFgHyo9u2338b58+fx2muvKVqoJ2FgkiKsTR0JDXVdPUQ+zq7AHDVqFNasWYM//elPmDt3runwqxACQUFBWL16NR566CFFC/UkVQMzLMx1dZAH4zxLIrdj9zzM6dOnY+zYsUhLS0NGRgaEEGjXrh2GDRuGRj7+i208hxkaKl/wnqheGJZEbqlegXnr1i18+umnOHfuHMLDwzF69Gj87ne/c1RtHquwUP6XS+JRvTEsidyWzYGZn5+PQYMG4YcffoAQApIkYd68efjyyy/Rp08fR9bocW7dkv9l75LqpbISuHHDfJ9hSeRWbB4l+8ILL+D777/Hgw8+iLfeegt//OMfUVJSgpkzZzqyPo9jMJiv2+vXoJV6yedUXamfYUnkdmz+SP/888/xwAMP4LPPPjNti42Nxbx583Dp0iVER0c7pEBPU3WJT39/19VBHiogQA5OHp4gcjs29zAvXbqEkSNHWmwbNWoUhBDIzMxUrKCUlBS0adMGOp0O8fHxOHDggE3PO3ToEPz8/NCjRw/FarFH1cBkD5Nuq7Ky5jaGJZFbsjkwy8rKEFZtjkSTJk1Mjylhy5YtmDNnDhYtWoT09HQMGDAAI0aMuG0gFxQUYOLEibjvvvsUqaMhGJhkK6m0FLh2DSgpcXUpRGSDeq30U9tyd0otg7d8+XJMnToV06ZNQ+fOnbFixQpER0dj9erVdT5vxowZGD9+PPr27atIHQ3BQ7JkE70eKuM14G7c4JJ3RB6gXn2gV155Be+//77pvnHN2Pnz56NptSVtJEnCF198YfNrl5eX49ixY5g/f77F9uHDh+Pw4cO1Pm/Dhg04d+4cPvjgA7zwwgu3/T5lZWUWPeLCX+eAGAwGGIyjdexgfH55uQFCyH9AqNUCDXhJr2Bsl4a0rdfR62HIyzO3S1CQfDiCbcT3Sy3YLtYp1S4qlW19x3oF5n//+1/897//rbH9u+++q7Gtvr3O3NxcVFZWonnz5hbbmzdvjqtXr1p9zk8//YT58+fjwIED8LPx+OeyZcuQnJxcY/ulS5cQ0oDLJQkhkJ+fj/JyP+j18iVKiopKkZlZaPdregNju0iS5NML8htJpaVQFRRACIGCggKIwEA5KI29TR/H94t1bBfrlGqX2NhYm/azOTCd9ZdN9R/aOOezusrKSowfPx7Jycno2LGjza+/YMECJCUlme4XFhYiOjoa0dHRCG3AOp0GgwFCCBgMLRAQoAYAREToEBPT2O7X9AbGdomOjrb5rzivZVyUIDgYBoMBlQEBaNW1K9ulCr5frGO7WOfsdnGbYSnh4eFQq9U1epPZ2dk1ep2AfFWUo0ePIj09HX/84x8BmBvPz88Pu3fvxpAhQ2o8T6vVQqvV1tiuUqka3OAqlQoVFSpTwPv7S+B729y2Pv2LrtfLvUhjGwQFQTIY2C5W8P1iHdvFOme2i9u0vEajQXx8PNLS0iy2p6WloV+/fjX2Dw0Nxffff48TJ06YvmbOnIk77rgDJ06cQO/evZ1VugUO+qEauNwdkVdwmx4mACQlJWHChAlISEhA37598c477yAzM9O0mtCCBQtw5coVbNy4ESqVCnFxcRbPb9asGXQ6XY3tzsTApBrUakCS5OtZGsOSgzeIPI5bBebYsWORl5eHpUuXIisrC3FxcdixYwdat24NAMjKylJ0kQRH4DxMqkGjkS+MWlrK61kSeTC3+0hPTExEYmKi1cdSU1PrfO6SJUuwZMkS5YuqB+PC6wADk6rQaLiCD5GHc5tzmN6CPUyCXm++xhsReQ1+pCuMgenjqg7wEYKDe4i8SIM+0s+fP4+vv/4a165dwxNPPIHY2FiUl5fj6tWriIyMhMYHD0Fx0I8Pqz4aloi8it2HZJ999ll07NgR06dPx3PPPYeMjAwAQGlpKbp06YKUlBTFivQkPIfpozh1hMjr2RWYa9euxauvvoqnnnoKu3fvhhDC9FhoaChGjx6Nzz//XLEiPQkPyfoghiWRT7ArMFNSUvDb3/4WK1aswF133VXj8W7duuHHH39scHGeqGoPk4dkfQDDkshn2BWYZ8+exbBhw2p9PCIiArm5uXYX5cnYw/QhDEsin2JXYOp0OhQXF9f6+MWLF9G4cWN7a/JoDEwfIQRQVGS+z7Ak8np2BWavXr2wfft2q4/p9Xps3LgR/fv3b1BhnoqjZH2EJMmr96jVDEsiH2FXYD7zzDM4cuQIfv/73yM9PR0AcOXKFXzxxRe49957ceXKFcybN0/RQj0Fe5g+RK0GIiIYlkQ+wq6P9KFDh2L16tV4+umnsXnzZgDA5MmTAchXHfn73/+Ovn37KlakJ+G0Ei9WViYvb1f1+qy81BKRz7D7I3369OkYPXo0tm7dijNnzkAIgY4dO+Kxxx5Dy5YtlazRozAwvZRxgI9WC4SFWYYmEfmEBn2kR0ZGYtasWUrV4hUqK823GZheoupo2LIyoKREPm9JRD6Fx5MUxkE/Xsba1BGGJZFPsqsPNGTIkNvuI0kSvv76a3te3qMxML0I51kSURV2BWZGRgakaudwKioqkJWVBYPBgPDwcAT56F/hHCXrJRiWRFSNXR/pFy5csLq9rKwMy5cvx4YNG7Bv376G1OWxOOjHCzAsicgKRc9harVaLFiwAL1790ZSUpKSL+0xKirMPW8GpgcqK2NYEpFVDhn0c88992DXrl2OeGm3x0OyHk6jkb8AhiURWXDIR/r58+dRXl7uiJd2ewxMD2dc8o5TR4ioGrs+0jMzM61uv379Or766iusXLkSgwYNakhdHst4DlOl4iIwHkMIy4UIJIlhSUQ12BWYsbGxNUbJGgkh0KlTJ6xcubJBhXkqYw+TvUsPodcDxcVyr5J/4RBRHez6WH/uuedqBKYkSQgLC0PHjh0xdOhQqHz0w8fYw+QcTA9QdTRsbi4QHs7QJKJa2RWYS5YsUbgM78EepoeoPnVEq2VYElGd6v0JcfPmTbRr1w4rVqxwQDmezxiY7GG6Mc6zJCI71Dswg4KCkJeXh+DgYEfU4/HYw3RzDEsispNdx6D69OmDY8eOKV2LV2BgujGGJRE1gF2B+dJLL2Hr1q3YuHGj0vV4POOgHwamm2FYElED2fyxnpmZiYiICAQEBCApKQmNGjXCk08+iXnz5qFt27YIDAy02N9Xr1bCUbJuqqzMfJthSUR2sDkw27Rpgw8++ADjxo0zXa0kJiYGAHDt2jWHFehJDAbzHHj2MN1M48byv5LEsCQiu9j8sS6EgBACQO1XK/F1XBbPzRlDk4jIDpx4pqCqVyrhIVkX0+str7VGRNRADEwFsYfpJowDfPLyGJpEpJh6faxv27YNP//8s037SpKEv/71r3YV5akqK3ktTJerOhrWYJDvs7tPRAqo18f69u3bsW3bNpv29cXAZA/TxaxNHQkNdV09RORV6vWxvnDhQgwdOtRRtXi8qj1MdmqcjPMsicjB6hWYnTt3xsCBAx1Vi8erOuiHPUwnYlgSkRNw0I+Cqo4vYWA6CcOSiJyEgakgDvpxsooKhiUROQ0DU0FVB/3wHKYT+PmZA5JhSUQOZnM/yGAwOLIOr8AepgsEBcmNrdW6uhIi8nLsYSqIPUwnqKysuY1hSUROwMBUEEfJOpheD2RnA6Wlrq6EiHwQA1NBXLjAgYyjYYWQ/+WSd0TkZAxMBfEcpoNUnzoSGMhj3kTkdAxMBVXt9PDzXCGcZ0lEboKBqSD2MBXGsCQiN8LAVBDPYSqIYUlEboaBqSBeQFohDEsickMMTAXxkKxCVCpA+rUtGZZE5Cb4sa4gHpJViFYLhIXJ8y0ZlkTkJvixriD2MBWk1XIFHyJyKzwkqyAujWcnvR4oLnZ1FUREdWI/SEFcGs8O1Qf4BAe7rhYiojqwh6kgXkC6nqqHpbWF1YmI3AQDU0E8h1kPnDpCRB6GgakgnsO0EcOSiDwQA1NB7GHagGFJRB6Kgamgqqfg2MO0gmFJRB7M7QIzJSUFbdq0gU6nQ3x8PA4cOFDrvtu2bcOwYcMQERGB0NBQ9O3bF7t27XJitZZu3WIPs1ZCAIWF5vsMSyLyMG4VmFu2bMGcOXOwaNEipKenY8CAARgxYgQyMzOt7r9//34MGzYMO3bswLFjxzB48GCMGjUK6enpTq5cVrWHycCsRpKApk3lZe8YlkTkgdzqY3358uWYOnUqpk2bBgBYsWIFdu3ahdWrV2PZsmU19l+xYoXF/b/97W/49NNP8fnnn+Ouu+5yRskWOA/zNvz8gIgIQK12dSVERPXmNh/r5eXlOHbsGObPn2+xffjw4Th8+LBNr2EwGFBUVISwsLBa9ykrK0NZWZnpfuGvhwkNBgMMBoMdlZu/tzwPU0ClAoQQEMLul/MO5eUw+PlZtq0kAQ1oZ29hbJOGvOe8EdvFOraLdUq1i0pl28FWtwnM3NxcVFZWonnz5hbbmzdvjqtXr9r0Gq+//jpu3ryJMWPG1LrPsmXLkJycXGP7pUuXEBISUr+iqxBC4ObNIOj1/tBoBDIzc+x+LW8glZZCVVAAg06H/IoKSJIESZJu/0QfIYRAfn4+26Uatot1bBfrlGqX2NhYm/Zzm8A0qv5DCyFsaojNmzdjyZIl+PTTT9GsWbNa91uwYAGSkpJM9wsLCxEdHY3o6GiEhobaXbfBYICfXwkCAnQICpIQExNj92t5PONo2OBg+a+/4mJER0fb/FecLzAYDBBCsF2qYbtYx3axztnt4jaBGR4eDrVaXaM3mZ2dXaPXWd2WLVswdepUbN26FUOHDq1zX61WC62Vq2CoVKoGN7g8D1OCRiNBpfLRvwL1eqCgQB7cAwBBQZAMBkXa19sY24TtYontYh3bxTpntovbtLxGo0F8fDzS0tIstqelpaFfv361Pm/z5s2YPHkyPvzwQzz44IOOLrNOxkE/Pjvgh/MsiciLudVHe1JSEiZMmICEhAT07dsX77zzDjIzMzFz5kwA8uHUK1euYOPGjQDksJw4cSLefPNN9OnTx9Q7DQgIQCMXfFAbp5X45KIFtYUlBykQkZdwq8AcO3Ys8vLysHTpUmRlZSEuLg47duxA69atAQBZWVkWczLXrl2LiooKPPXUU3jqqadM2ydNmoTU1FRnl++7PUz2LInIB7jdR3tiYiISExOtPlY9BPfu3ev4guqhslKeYuhTgVlayrAkIp/gNucwPZ0Q5qXxfCowNRrzMWiGJRF5MV/6aHcogwGmhQp8KjBVKnnJu5ISIDjY1dUQETkMe5gK8elrYapUDEsi8noMTIVUDUyv7mHq9UBuLrjuHxH5GgamQnyih2kcDVteDuTlMTSJyKcwMBUiL7wu88oeZvWpI/7+8kLqREQ+goGpEK8+JMt5lkREDEyleG1gMiyJiAAwMBXjlecwGZZERCYMTIV43TlMhiURkQUGpkK87pCsXm++zbAkImJgKsXrephNmgA6HcOSiOhX3vDR7ha87hymJMmhyakjREQA2MNUjMcfki0tNV/Q04hhSURkwsBUiEf3MPV64Pp1ecm76qFJREQAGJiK8dgeZtXRsJWV8lVHiIioBgamQjxy0I+1qSMhIa6rh4jIjTEwFeJxgcl5lkRE9cLAVIhHHZJlWBIR1RsDUyEeM+iHYUlEZBcGpkI8ood56xbDkojITgxMhXhED9PfHwgOlm8zLImI6sVd+0Iex2MG/YSGAhqNvOwdERHZjD1MhbjtIVmDoeY2hiURUb0xMBXiloGp1wPZ2UB5uasrISLyeAxMhbjdOUzjaFiDAcjLsyyQiIjqjYGpELfqYVafOhIY6AZFERF5NgamQtwmMDnPkojIIRiYCnGLUbIMSyIih2FgKsTlPUyGJRGRQzEwFeLSQT8MSyIih2NgKqSiQjLddnpgCmG+zbAkInIIDp1UiEsPyQYGyv/eusWwJCJyEAamQqoO+lGrXVCAMTSJiMgheEhWIcbA9PMDJKnufRtMrwdKShz8TYiIqCr2MBViPCTr8MOx1hYlICIih2MPUyFOCczqYVn1ODARETkUA1MhDg9MTh0hInIpBqZCjIHpkCklDEsiIpdjYCqk6qAfRTEsiYjcAgNTIQ45JMuwJCJyGwxMhSh+SNZgAAoKzPcZlkRELsXAVIAQDuhhqlRAWJg8qZNhSUTkcpyHqYDKSvNyrooektVogIgIXvyZiMgNsIepAMXWkbU2r5JhSUTkFhiYClDk0l56PZCTAxQWKlITEREpi4GpAMsepqh9x9pUHQ1bXAyUlipTGBERKYaBqYAG9TCtTR3R6RSpi4iIlMPAVEDVU4/1OuXIeZZERB6DgakAuwb9MCyJiDwKA1MB9Q5MhiURkcdhYCqgXodkS0sZlkREHoiBqYB69TD9/QG1Wr7NsCQi8hicFa+AegWmWg2EhwMlJUBIiEPrIiIi5bCHqYB6j5JVqxmWREQehoGpgDrnYer1wPXr5sVmiYjIIzEwFVDrIVnjaFjjQB+GJhGRx2JgKsBqYFafOqJWy5fqIiIij8TAVECNQ7KcZ0lE5HXcLjBTUlLQpk0b6HQ6xMfH48CBA3Xuv2/fPsTHx0On06Ft27ZYs2aNkyo1sxj0YyhjWBIReSG3CswtW7Zgzpw5WLRoEdLT0zFgwACMGDECmZmZVvc/f/48Ro4ciQEDBiA9PR0LFy7E7Nmz8cknnzi1bmNgSgYD/PTF5gcYlkREXsOtAnP58uWYOnUqpk2bhs6dO2PFihWIjo7G6tWrre6/Zs0axMTEYMWKFejcuTOmTZuGKVOm4LXXXnNq3RUVAAyVwK1b8FP/OrCHYUlE5FXcZuGC8vJyHDt2DPPnz7fYPnz4cBw+fNjqc44cOYLhw4dbbLv//vuxbt063Lp1C/5WrrVVVlaGsrIy0/3CXy/YbDAYYDAY7Kwdv6amgFptgCEgQJ5naefreRNju9rbtt6K7WId28U6tot1SrWLSmVb39FtAjM3NxeVlZVo3ry5xfbmzZvj6tWrVp9z9epVq/tXVFQgNzcXUVFRNZ6zbNkyJCcn19h+6dIlhNi5mMC1a0HQVwaiorIS10sKkVmgAQoK7HotbyOEQH5+PiRJgsRRwiZsF+vYLtaxXaxTql1iY2Nt2s9tAtOo+g8thKizIaztb2270YIFC5CUlGS6X1hYiOjoaERHRyM0NNSumnv1kr9vbo4eXXq1RUyMWx3pdimDwQAhBKKjo23+K84XsF2sY7tYx3axztnt4jaBGR4eDrVaXaM3mZ2dXaMXaRQZGWl1fz8/PzRt2tTqc7RaLbRabY3tKpXK7gbv0wfo1cuAzMxixMSE8Q1djbFt2S6W2C7WsV2sY7tY58x2cZuW12g0iI+PR1pamsX2tLQ09OvXz+pz+vbtW2P/3bt3IyEhwer5SyIiInu5TWACQFJSEt59912sX78ep0+fxty5c5GZmYmZM2cCkA+nTpw40bT/zJkzcfHiRSQlJeH06dNYv3491q1bh3nz5rnqRyAiIi/lNodkAWDs2LHIy8vD0qVLkZWVhbi4OOzYsQOtW7cGAGRlZVnMyWzTpg127NiBuXPnYtWqVWjRogVWrlyJRx991FU/AhEReSm3CkwASExMRGJiotXHUlNTa2wbOHAgjh8/7uCqiIjI17nVIVkiIiJ3xcAkIiKyAQOTiIjIBgxMIiIiGzAwiYiIbMDAJCIisgEDk4iIyAYMTCIiIhswMImIiGzAwCQiIrKB2y2N52zG62cWFhY26HUMBgOKiopQWFjIy+9UwXaxju1iHdvFOraLdUq2S0hIyG0vQu3zgVlUVAQAiI6OdnElRETkKgUFBQgNDa1zH0kYu1g+ymAw4JdffrHpr4u6FBYWIjo6GpcuXbpto/sStot1bBfr2C7WsV2sU7Jd2MO0gUqlQqtWrRR7vdDQUL6hrWC7WMd2sY7tYh3bxTpntQsPhhMREdmAgUlERGQDBqZCtFotFi9eDK1W6+pS3ArbxTq2i3VsF+vYLtY5u118ftAPERGRLdjDJCIisgEDk4iIyAYMTCIiIhswMImIiGzAwKyHlJQUtGnTBjqdDvHx8Thw4ECd++/btw/x8fHQ6XRo27Yt1qxZ46RKnas+7bJt2zYMGzYMERERCA0NRd++fbFr1y4nVus89X2/GB06dAh+fn7o0aOHYwt0kfq2S1lZGRYtWoTWrVtDq9WiXbt2WL9+vZOqdZ76tsumTZvQvXt3BAYGIioqCk8++STy8vKcVK3j7d+/H6NGjUKLFi0gSRL++c9/3vY5Dv/MFWSTjz76SPj7+4u///3v4tSpU+Lpp58WQUFB4uLFi1b3z8jIEIGBgeLpp58Wp06dEn//+9+Fv7+/+Pjjj51cuWPVt12efvpp8fLLL4tvv/1WnD17VixYsED4+/uL48ePO7lyx6pvuxjduHFDtG3bVgwfPlx0797dOcU6kT3tMnr0aNG7d2+RlpYmzp8/L/7zn/+IQ4cOObFqx6tvuxw4cECoVCrx5ptvioyMDHHgwAHRtWtX8cgjjzi5csfZsWOHWLRokfjkk08EALF9+/Y693fGZy4D00a9evUSM2fOtNjWqVMnMX/+fKv7//nPfxadOnWy2DZjxgzRp08fh9XoCvVtF2u6dOkikpOTlS7Npextl7Fjx4q//OUvYvHixV4ZmPVtly+//FI0atRI5OXlOaM8l6lvu7z66quibdu2FttWrlwpWrVq5bAaXcmWwHTGZy4PydqgvLwcx44dw/Dhwy22Dx8+HIcPH7b6nCNHjtTY//7778fRo0dx69Yth9XqTPa0S3XGy/OEhYU5okSXsLddNmzYgHPnzmHx4sWOLtEl7GmXzz77DAkJCXjllVfQsmVLdOzYEfPmzYNer3dGyU5hT7v069cPly9fxo4dOyCEwLVr1/Dxxx/jwQcfdEbJbskZn7k+v/i6LXJzc1FZWYnmzZtbbG/evDmuXr1q9TlXr161un9FRQVyc3MRFRXlsHqdxZ52qe7111/HzZs3MWbMGEeU6BL2tMtPP/2E+fPn48CBA/Dz885fS3vaJSMjAwcPHoROp8P27duRm5uLxMREXL9+3WvOY9rTLv369cOmTZswduxYlJaWoqKiAqNHj8Zbb73ljJLdkjM+c9nDrIfql34RQtR5ORhr+1vb7unq2y5GmzdvxpIlS7BlyxY0a9bMUeW5jK3tUllZifHjxyM5ORkdO3Z0VnkuU5/3i8FggCRJ2LRpE3r16oWRI0di+fLlSE1N9apeJlC/djl16hRmz56N5557DseOHcPOnTtx/vx5zJw50xmlui1Hf+Z655+yCgsPD4dara7x1152dnaNv2iMIiMjre7v5+eHpk2bOqxWZ7KnXYy2bNmCqVOnYuvWrRg6dKgjy3S6+rZLUVERjh49ivT0dPzxj38EIAeFEAJ+fn7YvXs3hgwZ4pTaHcme90tUVBRatmyJRo0ambZ17twZQghcvnwZHTp0cGjNzmBPuyxbtgz9+/fHM888AwDo1q0bgoKCMGDAALzwwgtecQSrvpzxmcsepg00Gg3i4+ORlpZmsT0tLQ39+vWz+py+ffvW2H/37t1ISEiAv7+/w2p1JnvaBZB7lpMnT8aHH37oledc6tsuoaGh+P7773HixAnT18yZM3HHHXfgxIkT6N27t7NKdyh73i/9+/fHL7/8guLiYtO2s2fPKn4dW1eyp11KSkqgUll+fKvVagDmXpWvccpnrmLDh7yccdj3unXrxKlTp8ScOXNEUFCQuHDhghBCiPnz54sJEyaY9jcOcZ47d644deqUWLdunVdPK7G1XT788EPh5+cnVq1aJbKyskxfN27ccNWP4BD1bZfqvHWUbH3bpaioSLRq1Ur87ne/EydPnhT79u0THTp0ENOmTXPVj+AQ9W2XDRs2CD8/P5GSkiLOnTsnDh48KBISEkSvXr1c9SMorqioSKSnp4v09HQBQCxfvlykp6ebptq44jOXgVkPq1atEq1btxYajUbcfffdYt++fabHJk2aJAYOHGix/969e8Vdd90lNBqNiI2NFatXr3Zyxc5Rn3YZOHCgAFDja9KkSc4v3MHq+36pylsDU4j6t8vp06fF0KFDRUBAgGjVqpVISkoSJSUlTq7a8erbLitXrhRdunQRAQEBIioqSjzxxBPi8uXLTq7acfbs2VPnZ4UrPnN5eS8iIiIb8BwmERGRDRiYRERENmBgEhER2YCBSUREZAMGJhERkQ0YmERERDZgYBIREdmAgUn0qyVLlkCSJFy4cMHVpThVamoqJEnC3r17bdp/7969kCQJqampDq2LyN0wMMljGT+4a/uyNQDcwYULF2rUHxgYiLi4OCQnJzv9yhwXLlzAkiVLcOLECad+X1tNnjzZoq3UajWaNWuGUaNG4eDBgw167RMnTmDJkiU+94cT3R6vVkIeb+zYsXjooYdqbO/cubMLqmmYIUOG4MknnwQA5OTkYMuWLViyZAkOHTqE3bt3O+R7TpgwAY8//jg0Go1p24ULF5CcnIzY2Fj06NHDYv97770Xer3eLS4i8Pbbb6NRo0YoLy/HyZMn8c4772Dnzp34+uuvce+999r1midOnEBycjIGDRqE2NhYZQsmj8bAJI/Xo0cP/P73v3d1GYro0KGDxc8ya9Ys9OrVC2lpafj222/Rq1cvxb+nWq02XenCFiqVCjqdTvE67PHoo48iMjLSdH/gwIF4+OGH8eqrr9odmES14SFZ8mrffvstJk+ejI4dOyIwMBAhISHo378/tm/fbtPzr1+/jqSkJLRr1w46nQ5NmjRBt27d8OKLL9bYd8uWLbjnnnsQEhKCwMBA9O7dGx9//HGD6vfz8zNdC/PcuXOm7Rs2bEBCQoLpZxo8eLDVHujhw4cxcuRIREZGQqvVIjIyEsOGDcOBAwdM+1Q/h7lkyRIMHjwYAPDkk0+aDntOnjwZQM1zmKdPn4YkSZg9e7bVn2HChAnw8/OzuFZhVlYW/u///g8xMTHQaDRo0aIFpk+fjuzsbLvbCgDuu+8+AMBPP/1ksf3MmTNITExE165dTf8/8fHx+Pvf/26x3+TJk009/MGDB5t+9iVLlpj2KSgowLPPPov27dtDq9UiIiIC48aNQ0ZGRoNqJ/fHHiZ5vJKSEuTm5lps02q1CAkJwfbt23H27FmMGzcOrVq1Ql5eHt577z389re/xaZNmzB+/Pg6X/uxxx7D/v37MWPGDHTv3h16vR5nz57F3r17sWjRItN+f/nLX/Diiy/igQcewPPPPw+1Wo3t27fjsccew9tvv42nnnrK7p/P+OEfHh4OAFi4cCGWLVuG+Ph4PP/88ygtLcW6devwwAMP4P3338cTTzwBAPjxxx8xbNgwREZGYvbs2YiMjER2djaOHDmC9PR0DBgwwOr3++1vf4tbt27hb3/7G6ZPn27ar127dlb379y5M3r27InNmzfj9ddftzhUW1xcjO3bt+P+++839QQzMzPRt29flJeXY+rUqWjXrh3OnTuHlJQU7NmzB0ePHrW4YHR9/PzzzwBQ44LBe/fuxcGDB/HII48gJiYGxcXF2Lp1K6ZPn47c3FwsWLAAADBjxgxotVq88847WLhwoemwfrdu3QDIYdmvXz9kZmZiypQp6Nq1K7KysrB69Wr07t0bR48eRevWre2qnTyAotc+IXKi2i7/A0A8/PDDQgghiouLazzv5s2bomPHjqJz584W2xcvXiwAiPPnzwshhLhx44YAIBITE+us4+jRowKAmD9/fo3HHn74YRESEiIKCwvrfI3z58+bLl2Uk5MjcnJyxKlTp8SiRYsEABEdHS30er348ccfhSRJonfv3qK0tNT0/NzcXBEZGSmaNGli+pnffPNNAUB8++23dX7vDRs2CABiz549pm3Gtt2wYUON/a099vbbbwsA4tNPP7XYNzU1VQAQW7ZsMW0bNWqUCA8PF5cuXbLY97vvvhNqtVosXry4znqFkC/tBECcPHlS5OTkiCtXroi0tDTRrVs3AUCsWrXKYv+bN2/WeI3KykoxcOBAERoaKsrLy+tsD6NZs2YJnU4nTpw4YbH9woULIiQkxCsvU0dmPCRLHm/q1KlIS0uz+Fq6dCkAICgoyLRfSUkJ8vLyUFJSgiFDhuD06dMoLCys9XUDAgKg0+nwzTff1Dli8sMPPwQATJw4Ebm5uRZfo0ePRlFREY4cOWLTz/Lee+8hIiICERER6NKlC1588UX069cPu3btgk6nw6effgohBP785z9Dq9Wante0aVMkJiYiPz8fe/bsAQA0btwYAPDPf/4TpaWlNn1/e40bNw4ajQYbN2602L5x40Y0btwYo0ePBgDcuHEDX3zxBR566CHodDqLtoqNjUX79u3rNbipa9euiIiIQMuWLTFs2DBcuHABL730EhITEy32CwwMNN0uLS1FXl4erl+/juHDh6OwsBBnzpy57fcSQuDDDz9E//790bJlS4vag4KC0KdPH4cNzCL3wEOy5PHat2+PoUOHWn0sOzsbf/nLX/Dpp59aPT9248YNhIaGWn2uRqPBm2++idmzZ6NNmzbo3LkzhgwZgocffhjDhg0z7Xf69GkAQJcuXWqt8dq1azb9LA899BCefvppSJIEnU6Htm3bIioqyvS48TxZ165dazz3zjvvtNjn8ccfx4cffoi//e1vWL58Ofr06YPhw4fj8ccfR5s2bWyqx1ZhYWF48MEH8a9//Qv5+flo0qQJLl++jL179+IPf/iDaZDQ2bNnYTAYkJqaWus8zrZt29r8ff/xj3+gSZMmKCoqwueff4733nsPwsolfouLi7FkyRL84x//wKVLl2o8np+ff9vvlZOTg7y8PHz99deIiIiwuo9KxT6IN2NgktcyGAwYNmwYzpw5g9mzZ6Nnz55o1KgR1Go1NmzYgA8//BAGg6HO15g+fTpGjx6NL774Avv378f27duxatUqPPLII/jkk0+gUqlMH9A7duyodaqFtYCzpmXLlrWGPwCrYVDbYxqNBjt37sTRo0exa9cu7N+/H8nJyUhOTsaGDRswbtw4m2qy1aRJk7B9+3Zs2bIFM2fOxPvvvw+DwYCJEyfWqHHcuHGYMmWK1dcJCAiw+XsOGDDAdG70N7/5DXQ6HRYsWIC7774bw4cPN+03btw4fPHFF5g+fTruvfdehIWFwc/PDzt27MAbb7xx2/dB1doHDx6MhQsX2lwjeQ8GJnmt77//Hv/73//w3HPPITk52eKxd9991+bXiYyMxNSpUzF16lQYDAb84Q9/wPr167Fv3z4MHjwYHTt2xM6dO9GqVStTL89RjANvTp48iTvuuMPisZMnT1rsY5SQkICEhAQsWrQIWVlZiI+Px/z58+sMTEmS6l3byJEjERERgY0bN5oCs3379ujXr59pn/bt20OSJJSVldX5h4G9XnzxRWzevBlz587F999/D5VKZToMPGHCBKxZs8Zi/6+++qrGa9T2s0dERKBx48YoKChwSO3k/nj8gLyWcW5h9Z7XDz/8YNO0kpKSEpSUlFhsU6lUpon8169fBwDTvMmFCxeioqKixus0dKpEVY888ggkScJrr72G8vJy0/br168jJSUFTZo0waBBgwCgxshhAIiKikJUVJSp9toEBwcDsO1QpZG/vz/GjRuHI0eOYPPmzTh9+jQmTZpksU/Tpk0xcuRIfPrppzh06FCN1xBCICcnx+bvWV2TJk0we/ZsnDp1Cps3bwZQ+/sgKyvL6h9Otf3sKpUKTzzxBI4fP46PPvrI6vdX8v+a3A97mOS1OnfujK5du+KVV15BSUkJ7rjjDpw9exZr165FXFwcjh8/Xufzz549i4EDB+I3v/kNunbtiqZNm+LMmTNYvXo1WrRoYepl9OzZE8nJyVi8eDF69OiBMWPGoEWLFsjKysKxY8ewY8cOi3BriA4dOmD+/PlYtmwZ+vfvj3HjxpmmlVy9ehUbN240DXR64YUXsHv3bjz00EOmc5Zffvkljh8/fttpLl26dEFwcDBSUlIQFBSE0NBQtGnTBr17967zeZMmTcLKlSsxc+ZMSJKECRMm1Nhn9erVuOeeezB48GBMmDABd999NwwGAzIyMvDpp59i4sSJFvMe62vOnDl44403sHTpUjz++OMICQnB8OHD8cEHHyAgIAA9e/bExYsXsXbtWrRp0wZ5eXkWz09ISIBKpcKyZcuQn59vWqIwLi4OL774Ig4dOoTx48dj+/bt6Nu3LzQaDS5evIgdO3YgPj6ea+x6MxeNziVqMOP0hmXLltW6z4ULF8Tvfvc7ER4eLgICAkTPnj3Ftm3bakwhEaLmtJLc3FwxZ84c0b17d9G4cWOh0+lE27ZtRWJiosjMzKzxvf71r3+J4cOHiyZNmgiNRiNatWolHnjgAZGSknLbn8U4rWTGjBk2/ezr1q0Td999t9DpdCIoKEgMHDhQ7Ny5s0b7jBkzRrRu3VrodDrRuHFjkZCQIFJSUkRFRYVpv9qmUXz22WeiW7duQqPRmKa8GF8XtUw5EUKIuLg4AUAMGjSo1vpzcnLEvHnzRIcOHYRWqxWNGjUScXFxYvbs2eLkyZO3/fmN00qysrKsPj5//nwBQKSmppq+39SpU0VUVJTQarUiLi5OvPPOO7X+7OvWrRMdO3YUfn5+AoDFVJebN2+KpUuXiri4OKHT6URwcLDo1KmTmDZtmvjmm29uWzt5LkmIOkYREBEREQCewyQiIrIJA5OIiMgGDEwiIiIbMDCJiIhswMAkIiKyAQOTiIjIBgxMIiIiGzAwiYiIbMDAJCIisgEDk4iIyAYMTCIiIhswMImIiGzAwCQiIrLB/wOWqx5SZVL3UgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='r',alpha=0.1)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "mean_tpr=np.mean(tprs,axis=0)\n",
    "mean_tpr[-1]=1.0\n",
    "std_auc=np.std(tprs,axis=0)\n",
    "plt.plot(mean_fpr,mean_tpr,color='b',label = u'AUC=%.3f' % (sum(auck)/5),lw=2,alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by Anaconda, Inc. | (main, Mar  8 2023, 10:42:25) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
