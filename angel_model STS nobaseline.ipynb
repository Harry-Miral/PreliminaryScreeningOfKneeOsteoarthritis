{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452b9946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T12:59:35.081622Z",
     "start_time": "2022-07-05T12:59:35.077621Z"
    }
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cf216bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:46.997604Z",
     "start_time": "2022-07-07T13:19:42.857680Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from pandas import read_csv, unique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import mode\n",
    "from scipy import interp\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow import stack\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, BatchNormalization, MaxPool1D, Reshape, Activation\n",
    "from keras.layers import Conv1D, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0860",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4351ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:47.013608Z",
     "start_time": "2022-07-07T13:19:46.998607Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    df = read_csv(filepath, header=None, names=['user-id',\n",
    "                                               'activity',\n",
    "                                               'timestamp',\n",
    "                                               'sex',\n",
    "                                               'age',\n",
    "                                               'BMI',\n",
    "                                               'A',\n",
    "                                               'B',\n",
    "                                               'C',\n",
    "                                               'X',\n",
    "                                               'Y',\n",
    "                                               'Z'])\n",
    "    ## removing ';' from last column and converting it to float\n",
    "    df['Z'].replace(regex=True, inplace=True, to_replace=r';', value=r'')\n",
    "    df['Z'] = df['Z'].apply(convert_to_float)\n",
    "#     df.dropna(axis=0, how='any', inplace=True)\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float64(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe14cbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:48.655211Z",
     "start_time": "2022-07-07T13:19:47.014608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.842979</td>\n",
       "      <td>142.253244</td>\n",
       "      <td>110.183184</td>\n",
       "      <td>132.892332</td>\n",
       "      <td>100.336497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.036722</td>\n",
       "      <td>141.564971</td>\n",
       "      <td>109.963102</td>\n",
       "      <td>132.264821</td>\n",
       "      <td>99.724264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.025532</td>\n",
       "      <td>141.226818</td>\n",
       "      <td>110.076491</td>\n",
       "      <td>131.910252</td>\n",
       "      <td>99.841460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.055731</td>\n",
       "      <td>139.674749</td>\n",
       "      <td>109.314311</td>\n",
       "      <td>130.638475</td>\n",
       "      <td>99.437923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.286753</td>\n",
       "      <td>138.646791</td>\n",
       "      <td>109.321849</td>\n",
       "      <td>129.840633</td>\n",
       "      <td>99.368373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>395.0</td>\n",
       "      <td>53.054386</td>\n",
       "      <td>101.282433</td>\n",
       "      <td>98.437307</td>\n",
       "      <td>91.694820</td>\n",
       "      <td>95.570696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>396.0</td>\n",
       "      <td>51.566923</td>\n",
       "      <td>104.802220</td>\n",
       "      <td>100.029568</td>\n",
       "      <td>98.373605</td>\n",
       "      <td>98.261446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>397.0</td>\n",
       "      <td>50.444408</td>\n",
       "      <td>106.489055</td>\n",
       "      <td>101.999649</td>\n",
       "      <td>101.329230</td>\n",
       "      <td>100.532071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>398.0</td>\n",
       "      <td>50.424259</td>\n",
       "      <td>106.749087</td>\n",
       "      <td>102.629601</td>\n",
       "      <td>101.878083</td>\n",
       "      <td>101.378611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>399.0</td>\n",
       "      <td>50.404110</td>\n",
       "      <td>107.009119</td>\n",
       "      <td>103.259553</td>\n",
       "      <td>102.426936</td>\n",
       "      <td>102.225152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp      A          B           C           X  \\\n",
       "0             1      Yes          0    0.0  38.842979  142.253244  110.183184   \n",
       "1             1      Yes          1    1.0  39.036722  141.564971  109.963102   \n",
       "2             1      Yes          2    2.0  39.025532  141.226818  110.076491   \n",
       "3             1      Yes          3    3.0  39.055731  139.674749  109.314311   \n",
       "4             1      Yes          4    4.0  39.286753  138.646791  109.321849   \n",
       "...         ...      ...        ...    ...        ...         ...         ...   \n",
       "142795      357      Yes        395  395.0  53.054386  101.282433   98.437307   \n",
       "142796      357      Yes        396  396.0  51.566923  104.802220  100.029568   \n",
       "142797      357      Yes        397  397.0  50.444408  106.489055  101.999649   \n",
       "142798      357      Yes        398  398.0  50.424259  106.749087  102.629601   \n",
       "142799      357      Yes        399  399.0  50.404110  107.009119  103.259553   \n",
       "\n",
       "                 Y           Z  \n",
       "0       132.892332  100.336497  \n",
       "1       132.264821   99.724264  \n",
       "2       131.910252   99.841460  \n",
       "3       130.638475   99.437923  \n",
       "4       129.840633   99.368373  \n",
       "...            ...         ...  \n",
       "142795   91.694820   95.570696  \n",
       "142796   98.373605   98.261446  \n",
       "142797  101.329230  100.532071  \n",
       "142798  101.878083  101.378611  \n",
       "142799  102.426936  102.225152  \n",
       "\n",
       "[142800 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data('Dataset/Angel_and_Baseline/Angel_data_STS_order.txt')\n",
    "df = df.drop(labels=['sex', 'age','BMI'], axis=1) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfc0f2",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78699eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.436290Z",
     "start_time": "2022-07-07T13:19:50.281071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.842979</td>\n",
       "      <td>142.253244</td>\n",
       "      <td>110.183184</td>\n",
       "      <td>132.892332</td>\n",
       "      <td>100.336497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.036722</td>\n",
       "      <td>141.564971</td>\n",
       "      <td>109.963102</td>\n",
       "      <td>132.264821</td>\n",
       "      <td>99.724264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.025532</td>\n",
       "      <td>141.226818</td>\n",
       "      <td>110.076491</td>\n",
       "      <td>131.910252</td>\n",
       "      <td>99.841460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.055731</td>\n",
       "      <td>139.674749</td>\n",
       "      <td>109.314311</td>\n",
       "      <td>130.638475</td>\n",
       "      <td>99.437923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.286753</td>\n",
       "      <td>138.646791</td>\n",
       "      <td>109.321849</td>\n",
       "      <td>129.840633</td>\n",
       "      <td>99.368373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>395.0</td>\n",
       "      <td>53.054386</td>\n",
       "      <td>101.282433</td>\n",
       "      <td>98.437307</td>\n",
       "      <td>91.694820</td>\n",
       "      <td>95.570696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>396.0</td>\n",
       "      <td>51.566923</td>\n",
       "      <td>104.802220</td>\n",
       "      <td>100.029568</td>\n",
       "      <td>98.373605</td>\n",
       "      <td>98.261446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>397.0</td>\n",
       "      <td>50.444408</td>\n",
       "      <td>106.489055</td>\n",
       "      <td>101.999649</td>\n",
       "      <td>101.329230</td>\n",
       "      <td>100.532071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>398.0</td>\n",
       "      <td>50.424259</td>\n",
       "      <td>106.749087</td>\n",
       "      <td>102.629601</td>\n",
       "      <td>101.878083</td>\n",
       "      <td>101.378611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>399.0</td>\n",
       "      <td>50.404110</td>\n",
       "      <td>107.009119</td>\n",
       "      <td>103.259553</td>\n",
       "      <td>102.426936</td>\n",
       "      <td>102.225152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp      A          B           C           X  \\\n",
       "0             1      Yes          0    0.0  38.842979  142.253244  110.183184   \n",
       "1             1      Yes          1    1.0  39.036722  141.564971  109.963102   \n",
       "2             1      Yes          2    2.0  39.025532  141.226818  110.076491   \n",
       "3             1      Yes          3    3.0  39.055731  139.674749  109.314311   \n",
       "4             1      Yes          4    4.0  39.286753  138.646791  109.321849   \n",
       "...         ...      ...        ...    ...        ...         ...         ...   \n",
       "142795      357      Yes        395  395.0  53.054386  101.282433   98.437307   \n",
       "142796      357      Yes        396  396.0  51.566923  104.802220  100.029568   \n",
       "142797      357      Yes        397  397.0  50.444408  106.489055  101.999649   \n",
       "142798      357      Yes        398  398.0  50.424259  106.749087  102.629601   \n",
       "142799      357      Yes        399  399.0  50.404110  107.009119  103.259553   \n",
       "\n",
       "                 Y           Z  activityEncode  \n",
       "0       132.892332  100.336497               1  \n",
       "1       132.264821   99.724264               1  \n",
       "2       131.910252   99.841460               1  \n",
       "3       130.638475   99.437923               1  \n",
       "4       129.840633   99.368373               1  \n",
       "...            ...         ...             ...  \n",
       "142795   91.694820   95.570696               1  \n",
       "142796   98.373605   98.261446               1  \n",
       "142797  101.329230  100.532071               1  \n",
       "142798  101.878083  101.378611               1  \n",
       "142799  102.426936  102.225152               1  \n",
       "\n",
       "[142800 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode = LabelEncoder()\n",
    "df['activityEncode'] = label_encode.fit_transform(df['activity'].values.ravel())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be5152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T16:53:26.834976Z",
     "start_time": "2022-07-04T16:53:26.823973Z"
    }
   },
   "source": [
    "## Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7951cd31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.484301Z",
     "start_time": "2022-07-07T13:19:50.437290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6d9e58d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.532284Z",
     "start_time": "2022-07-07T13:19:50.485302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.interpolate._interpolate.interp1d at 0x211a1f4ae80>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation_fn = interp1d(df['activityEncode'] ,df['Z'], kind='linear')\n",
    "interpolation_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f8ea8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.548288Z",
     "start_time": "2022-07-07T13:19:50.534285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_list = df[df['Z'].isnull()].index.tolist()\n",
    "null_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f002bca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.580295Z",
     "start_time": "2022-07-07T13:19:50.549289Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in null_list:\n",
    "    y = df['activityEncode'][i]\n",
    "    value = interpolation_fn(y)\n",
    "    df['Z']=df['Z'].fillna(value)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4349e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.627795Z",
     "start_time": "2022-07-07T13:19:50.581295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abe57c",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a24a047f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433618</td>\n",
       "      <td>0.712609</td>\n",
       "      <td>0.423799</td>\n",
       "      <td>0.650296</td>\n",
       "      <td>0.335294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.436683</td>\n",
       "      <td>0.707362</td>\n",
       "      <td>0.421885</td>\n",
       "      <td>0.645632</td>\n",
       "      <td>0.329743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.436506</td>\n",
       "      <td>0.704784</td>\n",
       "      <td>0.422871</td>\n",
       "      <td>0.642997</td>\n",
       "      <td>0.330805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.436984</td>\n",
       "      <td>0.692951</td>\n",
       "      <td>0.416241</td>\n",
       "      <td>0.633544</td>\n",
       "      <td>0.327147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.440639</td>\n",
       "      <td>0.685113</td>\n",
       "      <td>0.416307</td>\n",
       "      <td>0.627614</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.658435</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.321626</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.292085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.634904</td>\n",
       "      <td>0.427078</td>\n",
       "      <td>0.335476</td>\n",
       "      <td>0.393726</td>\n",
       "      <td>0.316480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.617146</td>\n",
       "      <td>0.439938</td>\n",
       "      <td>0.352614</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.337067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.616828</td>\n",
       "      <td>0.441921</td>\n",
       "      <td>0.358093</td>\n",
       "      <td>0.419774</td>\n",
       "      <td>0.344742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616509</td>\n",
       "      <td>0.443904</td>\n",
       "      <td>0.363573</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.352417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp         A         B         C         X  \\\n",
       "0             1      Yes          0  0.000000  0.433618  0.712609  0.423799   \n",
       "1             1      Yes          1  0.002506  0.436683  0.707362  0.421885   \n",
       "2             1      Yes          2  0.005013  0.436506  0.704784  0.422871   \n",
       "3             1      Yes          3  0.007519  0.436984  0.692951  0.416241   \n",
       "4             1      Yes          4  0.010025  0.440639  0.685113  0.416307   \n",
       "...         ...      ...        ...       ...       ...       ...       ...   \n",
       "142795      357      Yes        395  0.989975  0.658435  0.400242  0.321626   \n",
       "142796      357      Yes        396  0.992481  0.634904  0.427078  0.335476   \n",
       "142797      357      Yes        397  0.994987  0.617146  0.439938  0.352614   \n",
       "142798      357      Yes        398  0.997494  0.616828  0.441921  0.358093   \n",
       "142799      357      Yes        399  1.000000  0.616509  0.443904  0.363573   \n",
       "\n",
       "               Y         Z  activityEncode  \n",
       "0       0.650296  0.335294               1  \n",
       "1       0.645632  0.329743               1  \n",
       "2       0.642997  0.330805               1  \n",
       "3       0.633544  0.327147               1  \n",
       "4       0.627614  0.326516               1  \n",
       "...          ...       ...             ...  \n",
       "142795  0.344084  0.292085               1  \n",
       "142796  0.393726  0.316480               1  \n",
       "142797  0.415694  0.337067               1  \n",
       "142798  0.419774  0.344742               1  \n",
       "142799  0.423853  0.352417               1  \n",
       "\n",
       "[142800 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['age'] = (df['age']-df['age'].min())/(df['age'].max()-df['age'].min())\n",
    "#df['BMI'] = (df['BMI']-df['BMI'].min())/(df['BMI'].max()-df['BMI'].min())\n",
    "df['A'] = (df['A']-df['A'].min())/(df['A'].max()-df['A'].min())\n",
    "df['B'] = (df['B']-df['B'].min())/(df['B'].max()-df['B'].min())\n",
    "df['C'] = (df['C']-df['C'].min())/(df['C'].max()-df['C'].min())\n",
    "df['X'] = (df['X']-df['X'].min())/(df['X'].max()-df['X'].min())\n",
    "df['Y'] = (df['Y']-df['Y'].min())/(df['Y'].max()-df['Y'].min())\n",
    "df['Z'] = (df['Z']-df['Z'].min())/(df['Z'].max()-df['Z'].min())\n",
    "#df['sex'] = (df['sex']-df['sex'].min())/(df['sex'].max()-df['sex'].min())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a31ec3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments(df, time_steps, step, label_name):\n",
    "    N_FEATURES = 6\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['X'].values[i:i+time_steps]\n",
    "        ys = df['Y'].values[i:i+time_steps]\n",
    "        zs = df['Z'].values[i:i+time_steps]\n",
    "        aas = df['A'].values[i:i+time_steps]\n",
    "        bs = df['B'].values[i:i+time_steps]\n",
    "        cs = df['C'].values[i:i+time_steps]\n",
    "        #sexs = df['sex'].values[i:i+time_steps]\n",
    "        #ages = df['age'].values[i:i+time_steps]\n",
    "        #bmis = df['BMI'].values[i:i+time_steps]\n",
    "        label = mode(df[label_name][i:i+time_steps])[0][0]\n",
    "        segments.append([aas,bs,cs,xs, ys, zs])#sexs,ages,bmis,\n",
    "        labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype=np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "987cccea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433618</td>\n",
       "      <td>0.712609</td>\n",
       "      <td>0.423799</td>\n",
       "      <td>0.650296</td>\n",
       "      <td>0.335294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.436683</td>\n",
       "      <td>0.707362</td>\n",
       "      <td>0.421885</td>\n",
       "      <td>0.645632</td>\n",
       "      <td>0.329743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.436506</td>\n",
       "      <td>0.704784</td>\n",
       "      <td>0.422871</td>\n",
       "      <td>0.642997</td>\n",
       "      <td>0.330805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.436984</td>\n",
       "      <td>0.692951</td>\n",
       "      <td>0.416241</td>\n",
       "      <td>0.633544</td>\n",
       "      <td>0.327147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.440639</td>\n",
       "      <td>0.685113</td>\n",
       "      <td>0.416307</td>\n",
       "      <td>0.627614</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.658435</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.321626</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.292085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.634904</td>\n",
       "      <td>0.427078</td>\n",
       "      <td>0.335476</td>\n",
       "      <td>0.393726</td>\n",
       "      <td>0.316480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.617146</td>\n",
       "      <td>0.439938</td>\n",
       "      <td>0.352614</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.337067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.616828</td>\n",
       "      <td>0.441921</td>\n",
       "      <td>0.358093</td>\n",
       "      <td>0.419774</td>\n",
       "      <td>0.344742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616509</td>\n",
       "      <td>0.443904</td>\n",
       "      <td>0.363573</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.352417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp         A         B         C         X  \\\n",
       "0             1      Yes          0  0.000000  0.433618  0.712609  0.423799   \n",
       "1             1      Yes          1  0.002506  0.436683  0.707362  0.421885   \n",
       "2             1      Yes          2  0.005013  0.436506  0.704784  0.422871   \n",
       "3             1      Yes          3  0.007519  0.436984  0.692951  0.416241   \n",
       "4             1      Yes          4  0.010025  0.440639  0.685113  0.416307   \n",
       "...         ...      ...        ...       ...       ...       ...       ...   \n",
       "142795      357      Yes        395  0.989975  0.658435  0.400242  0.321626   \n",
       "142796      357      Yes        396  0.992481  0.634904  0.427078  0.335476   \n",
       "142797      357      Yes        397  0.994987  0.617146  0.439938  0.352614   \n",
       "142798      357      Yes        398  0.997494  0.616828  0.441921  0.358093   \n",
       "142799      357      Yes        399  1.000000  0.616509  0.443904  0.363573   \n",
       "\n",
       "               Y         Z  activityEncode  \n",
       "0       0.650296  0.335294               1  \n",
       "1       0.645632  0.329743               1  \n",
       "2       0.642997  0.330805               1  \n",
       "3       0.633544  0.327147               1  \n",
       "4       0.627614  0.326516               1  \n",
       "...          ...       ...             ...  \n",
       "142795  0.344084  0.292085               1  \n",
       "142796  0.393726  0.316480               1  \n",
       "142797  0.415694  0.337067               1  \n",
       "142798  0.419774  0.344742               1  \n",
       "142799  0.423853  0.352417               1  \n",
       "\n",
       "[142800 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b783875",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PERIOD = 80\n",
    "STEP_DISTANCE = 40\n",
    "LABEL = 'activityEncode'\n",
    "\n",
    "df1=df[df['user-id']>70]\n",
    "df2=df[df['user-id']>140]\n",
    "df3=df[df['user-id']>210]\n",
    "df4=df[df['user-id']>280]\n",
    "\n",
    "a1=df.shape[0]\n",
    "b2=df1.shape[0]\n",
    "c3=df2.shape[0]\n",
    "d4=df3.shape[0]\n",
    "e5=df4.shape[0]\n",
    "\n",
    "df_test0 = df.iloc[0:a1-b2,:]\n",
    "df_train0 = df.iloc[a1-b2:a1,:]\n",
    "x_train0, y_train0 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test0, y_test0 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train0.shape[1], x_train0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train0 = x_train0.reshape(x_train0.shape[0], input_shape)\n",
    "x_train0 = x_train0.astype('float32')\n",
    "y_train0=np.asarray(y_train0).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test0.shape[1], x_test0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test0 = x_test0.reshape(x_test0.shape[0], input_shape)\n",
    "x_test0 = x_test0.astype('float32')\n",
    "y_test0=np.asarray(y_test0).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test1 = df.iloc[a1-b2:a1-c3,:]\n",
    "df_train1 = pd.concat([df_test0,df.iloc[a1-c3:a1,]])\n",
    "x_train1, y_train1 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test1, y_test1 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train1.shape[1], x_train1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train1 = x_train1.reshape(x_train1.shape[0], input_shape)\n",
    "x_train1 = x_train1.astype('float32')\n",
    "y_train1=np.asarray(y_train1).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test1.shape[1], x_test1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0], input_shape)\n",
    "x_test1 = x_test1.astype('float32')\n",
    "y_test1=np.asarray(y_test1).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test2 = df.iloc[a1-c3:a1-d4,:]\n",
    "df_train2 = pd.concat([df.iloc[0:a1-c3,:],df.iloc[a1-d4:a1,]])\n",
    "x_train2, y_train2 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test2, y_test2 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train2.shape[1], x_train2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train2 = x_train2.reshape(x_train2.shape[0], input_shape)\n",
    "x_train2 = x_train2.astype('float32')\n",
    "y_train2=np.asarray(y_train2).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test2.shape[1], x_test2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test2 = x_test2.reshape(x_test2.shape[0], input_shape)\n",
    "x_test2 = x_test2.astype('float32')\n",
    "y_test2=np.asarray(y_test2).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test3 = df.iloc[a1-d4:a1-e5,:]\n",
    "df_train3 = pd.concat([df.iloc[0:a1-d4,:],df.iloc[a1-e5:a1,]])\n",
    "x_train3, y_train3 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test3, y_test3 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train3.shape[1], x_train3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train3 = x_train3.reshape(x_train3.shape[0], input_shape)\n",
    "x_train3 = x_train3.astype('float32')\n",
    "y_train3=np.asarray(y_train3).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test3.shape[1], x_test3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test3 = x_test3.reshape(x_test3.shape[0], input_shape)\n",
    "x_test3 = x_test3.astype('float32')\n",
    "y_test3=np.asarray(y_test3).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test4 = df.iloc[a1-e5:a1,:]\n",
    "df_train4 = df.iloc[0:a1-e5,:]\n",
    "x_train4, y_train4 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test4, y_test4 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train4.shape[1], x_train4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train4 = x_train4.reshape(x_train4.shape[0], input_shape)\n",
    "x_train4 = x_train4.astype('float32')\n",
    "y_train4=np.asarray(y_train4).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test4.shape[1], x_test4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test4 = x_test4.reshape(x_test4.shape[0], input_shape)\n",
    "x_test4 = x_test4.astype('float32')\n",
    "y_test4=np.asarray(y_test4).astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40c9e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 480, 32)           4352      \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 480, 32)           8320      \n",
      "                                                                 \n",
      " reshape_18 (Reshape)        (None, 1, 480, 32)        0         \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 1, 240, 64)        4160      \n",
      "                                                                 \n",
      " reshape_19 (Reshape)        (None, 240, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 60, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 59, 192)           24768     \n",
      "                                                                 \n",
      " reshape_20 (Reshape)        (None, 59, 192)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d_6   (None, 192)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 192)              768       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 193       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,561\n",
      "Trainable params: 42,177\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model.add(Reshape((1, 480, 32)))\n",
    "model.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model.add(Reshape((240, 64)))\n",
    "model.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model.add(Reshape((59, 192)))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(BatchNormalization(epsilon=1e-06))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1538a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.0001\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 5.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "sgd = SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False)\n",
    "adam=optimizers.Adam(lr=0.000135, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "#lr_metric = get_lr_metric(adam)\n",
    "lr_metric = get_lr_metric(adam)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model1.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model1.add(Reshape((1, 480, 32)))\n",
    "model1.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model1.add(Reshape((240, 64)))\n",
    "model1.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model1.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model1.add(Reshape((59, 192)))\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(BatchNormalization(epsilon=1e-06))\n",
    "model1.add(Dense(1))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model2.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model2.add(Reshape((1, 480, 32)))\n",
    "model2.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model2.add(Reshape((240, 64)))\n",
    "model2.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model2.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model2.add(Reshape((59, 192)))\n",
    "model2.add(GlobalAveragePooling1D())\n",
    "model2.add(BatchNormalization(epsilon=1e-06))\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model3.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model3.add(Reshape((1, 480, 32)))\n",
    "model3.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model3.add(Reshape((240, 64)))\n",
    "model3.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model3.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model3.add(Reshape((59, 192)))\n",
    "model3.add(GlobalAveragePooling1D())\n",
    "model3.add(BatchNormalization(epsilon=1e-06))\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model4.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model4.add(Reshape((1, 480, 32)))\n",
    "model4.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model4.add(Reshape((240, 64)))\n",
    "model4.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model4.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model4.add(Reshape((59, 192)))\n",
    "model4.add(GlobalAveragePooling1D())\n",
    "model4.add(BatchNormalization(epsilon=1e-06))\n",
    "model4.add(Dense(1))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model5.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model5.add(Reshape((1, 480, 32)))\n",
    "model5.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model5.add(Reshape((240, 64)))\n",
    "model5.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model5.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model5.add(Reshape((59, 192)))\n",
    "model5.add(GlobalAveragePooling1D())\n",
    "model5.add(BatchNormalization(epsilon=1e-06))\n",
    "model5.add(Dense(1))\n",
    "model5.add(Activation('sigmoid'))\n",
    "model5.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2047136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 7s 191ms/step - loss: 0.6696 - accuracy: 0.6220 - lr: 1.3500e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 5s 187ms/step - loss: 0.6165 - accuracy: 0.7036 - lr: 1.3500e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 5s 189ms/step - loss: 0.5854 - accuracy: 0.7329 - lr: 1.3500e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.5621 - accuracy: 0.7549 - lr: 1.3500e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 6s 190ms/step - loss: 0.5443 - accuracy: 0.7622 - lr: 1.3500e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.5216 - accuracy: 0.7772 - lr: 1.3500e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.5090 - accuracy: 0.7807 - lr: 1.3500e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.5009 - accuracy: 0.7870 - lr: 1.3500e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.4862 - accuracy: 0.7957 - lr: 1.3500e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.4742 - accuracy: 0.8051 - lr: 1.3500e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.4713 - accuracy: 0.8047 - lr: 1.3500e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.4638 - accuracy: 0.8047 - lr: 1.3500e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.4595 - accuracy: 0.8072 - lr: 1.3500e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.4562 - accuracy: 0.8114 - lr: 1.3500e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.4561 - accuracy: 0.8187 - lr: 1.3500e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.4488 - accuracy: 0.8162 - lr: 1.3500e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.4420 - accuracy: 0.8166 - lr: 1.3500e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 6s 199ms/step - loss: 0.4428 - accuracy: 0.8149 - lr: 1.3500e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.4347 - accuracy: 0.8215 - lr: 1.3500e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.4340 - accuracy: 0.8128 - lr: 1.3500e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.4312 - accuracy: 0.8201 - lr: 1.3500e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.4543 - accuracy: 0.8075 - lr: 1.3500e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 6s 193ms/step - loss: 0.4311 - accuracy: 0.8201 - lr: 1.3500e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 6s 201ms/step - loss: 0.4159 - accuracy: 0.8225 - lr: 1.3500e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.4220 - accuracy: 0.8264 - lr: 1.3500e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.4127 - accuracy: 0.8239 - lr: 1.3500e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.4116 - accuracy: 0.8323 - lr: 1.3500e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.4084 - accuracy: 0.8264 - lr: 1.3500e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.4041 - accuracy: 0.8319 - lr: 1.3500e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.3993 - accuracy: 0.8333 - lr: 1.3500e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.3933 - accuracy: 0.8316 - lr: 1.3500e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.3936 - accuracy: 0.8330 - lr: 1.3500e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 6s 199ms/step - loss: 0.3905 - accuracy: 0.8379 - lr: 1.3500e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.4005 - accuracy: 0.8229 - lr: 1.3500e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 6s 201ms/step - loss: 0.3913 - accuracy: 0.8309 - lr: 1.3500e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.3867 - accuracy: 0.8427 - lr: 1.3500e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3866 - accuracy: 0.8340 - lr: 1.3500e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.3850 - accuracy: 0.8382 - lr: 1.3500e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 6s 192ms/step - loss: 0.3786 - accuracy: 0.8347 - lr: 1.3500e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 6s 192ms/step - loss: 0.3849 - accuracy: 0.8372 - lr: 1.3500e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 6s 201ms/step - loss: 0.3808 - accuracy: 0.8372 - lr: 1.3500e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3731 - accuracy: 0.8410 - lr: 1.3500e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3768 - accuracy: 0.8368 - lr: 1.3500e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.3689 - accuracy: 0.8403 - lr: 1.3500e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3676 - accuracy: 0.8441 - lr: 1.3500e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.3664 - accuracy: 0.8476 - lr: 1.3500e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.3663 - accuracy: 0.8389 - lr: 1.3500e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3728 - accuracy: 0.8365 - lr: 1.3500e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.3705 - accuracy: 0.8358 - lr: 1.3500e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3520 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3528 - accuracy: 0.8462 - lr: 1.3500e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.3585 - accuracy: 0.8396 - lr: 1.3500e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.3532 - accuracy: 0.8476 - lr: 1.3500e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3518 - accuracy: 0.8434 - lr: 1.3500e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.3462 - accuracy: 0.8448 - lr: 1.3500e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.3521 - accuracy: 0.8469 - lr: 1.3500e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.3539 - accuracy: 0.8459 - lr: 1.3500e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3547 - accuracy: 0.8487 - lr: 1.3500e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3420 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3419 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3536 - accuracy: 0.8441 - lr: 1.3500e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3442 - accuracy: 0.8473 - lr: 1.3500e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.3433 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 7s 227ms/step - loss: 0.3494 - accuracy: 0.8476 - lr: 1.3500e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 7s 229ms/step - loss: 0.3457 - accuracy: 0.8480 - lr: 1.3500e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3383 - accuracy: 0.8525 - lr: 1.3500e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3473 - accuracy: 0.8480 - lr: 1.3500e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 7s 232ms/step - loss: 0.3419 - accuracy: 0.8518 - lr: 1.3500e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.3447 - accuracy: 0.8466 - lr: 1.3500e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 7s 227ms/step - loss: 0.3492 - accuracy: 0.8462 - lr: 1.3500e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.3436 - accuracy: 0.8529 - lr: 1.3500e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3369 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.3344 - accuracy: 0.8546 - lr: 1.3500e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3332 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3517 - accuracy: 0.8386 - lr: 1.3500e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3456 - accuracy: 0.8466 - lr: 1.3500e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3453 - accuracy: 0.8525 - lr: 1.3500e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.3404 - accuracy: 0.8469 - lr: 1.3500e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 6s 199ms/step - loss: 0.3331 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.3352 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 6s 201ms/step - loss: 0.3398 - accuracy: 0.8448 - lr: 1.3500e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3296 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3312 - accuracy: 0.8577 - lr: 1.3500e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 6s 201ms/step - loss: 0.3364 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3298 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.3389 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3277 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3366 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3307 - accuracy: 0.8539 - lr: 1.3500e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.3317 - accuracy: 0.8525 - lr: 1.3500e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 6s 198ms/step - loss: 0.3211 - accuracy: 0.8605 - lr: 1.3500e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3206 - accuracy: 0.8679 - lr: 1.3500e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.3259 - accuracy: 0.8546 - lr: 1.3500e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.3275 - accuracy: 0.8570 - lr: 1.3500e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.3362 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3387 - accuracy: 0.8532 - lr: 1.3500e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.3329 - accuracy: 0.8529 - lr: 1.3500e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.3251 - accuracy: 0.8616 - lr: 1.3500e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.3386 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.3245 - accuracy: 0.8623 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.6668 - accuracy: 0.7636 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 37ms/step\n",
      "22/22 [==============================] - 1s 37ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 7s 200ms/step - loss: 0.5975 - accuracy: 0.7144 - lr: 1.3500e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.5038 - accuracy: 0.7793 - lr: 1.3500e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.4681 - accuracy: 0.7943 - lr: 1.3500e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.4568 - accuracy: 0.7971 - lr: 1.3500e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.4552 - accuracy: 0.8009 - lr: 1.3500e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.4419 - accuracy: 0.8107 - lr: 1.3500e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.4295 - accuracy: 0.8204 - lr: 1.3500e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.4236 - accuracy: 0.8208 - lr: 1.3500e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.4227 - accuracy: 0.8187 - lr: 1.3500e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.4185 - accuracy: 0.8236 - lr: 1.3500e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 0.4115 - accuracy: 0.8229 - lr: 1.3500e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.4121 - accuracy: 0.8197 - lr: 1.3500e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.4088 - accuracy: 0.8257 - lr: 1.3500e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.4027 - accuracy: 0.8288 - lr: 1.3500e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.4035 - accuracy: 0.8243 - lr: 1.3500e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3986 - accuracy: 0.8358 - lr: 1.3500e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3936 - accuracy: 0.8323 - lr: 1.3500e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3922 - accuracy: 0.8344 - lr: 1.3500e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3826 - accuracy: 0.8396 - lr: 1.3500e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3855 - accuracy: 0.8403 - lr: 1.3500e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3848 - accuracy: 0.8375 - lr: 1.3500e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3815 - accuracy: 0.8414 - lr: 1.3500e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3726 - accuracy: 0.8434 - lr: 1.3500e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3876 - accuracy: 0.8333 - lr: 1.3500e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3737 - accuracy: 0.8410 - lr: 1.3500e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3698 - accuracy: 0.8431 - lr: 1.3500e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3674 - accuracy: 0.8403 - lr: 1.3500e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3645 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3639 - accuracy: 0.8452 - lr: 1.3500e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3711 - accuracy: 0.8427 - lr: 1.3500e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3659 - accuracy: 0.8511 - lr: 1.3500e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3653 - accuracy: 0.8427 - lr: 1.3500e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3583 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.3651 - accuracy: 0.8445 - lr: 1.3500e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3553 - accuracy: 0.8504 - lr: 1.3500e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3702 - accuracy: 0.8386 - lr: 1.3500e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3636 - accuracy: 0.8417 - lr: 1.3500e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3510 - accuracy: 0.8529 - lr: 1.3500e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3569 - accuracy: 0.8414 - lr: 1.3500e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3486 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3635 - accuracy: 0.8452 - lr: 1.3500e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3542 - accuracy: 0.8511 - lr: 1.3500e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3539 - accuracy: 0.8494 - lr: 1.3500e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3565 - accuracy: 0.8455 - lr: 1.3500e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3472 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3540 - accuracy: 0.8466 - lr: 1.3500e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3524 - accuracy: 0.8476 - lr: 1.3500e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3486 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3420 - accuracy: 0.8570 - lr: 1.3500e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3514 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3556 - accuracy: 0.8438 - lr: 1.3500e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3478 - accuracy: 0.8546 - lr: 1.3500e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3432 - accuracy: 0.8525 - lr: 1.3500e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3571 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3454 - accuracy: 0.8511 - lr: 1.3500e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3462 - accuracy: 0.8553 - lr: 1.3500e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3448 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3512 - accuracy: 0.8508 - lr: 1.3500e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3462 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3463 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3459 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3449 - accuracy: 0.8539 - lr: 1.3500e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3429 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3376 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3365 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3341 - accuracy: 0.8560 - lr: 1.3500e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3403 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 6s 202ms/step - loss: 0.3326 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3488 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3474 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3393 - accuracy: 0.8591 - lr: 1.3500e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3416 - accuracy: 0.8497 - lr: 1.3500e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3377 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3396 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.3409 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3410 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3366 - accuracy: 0.8577 - lr: 1.3500e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3335 - accuracy: 0.8595 - lr: 1.3500e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3291 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.3439 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3330 - accuracy: 0.8560 - lr: 1.3500e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3335 - accuracy: 0.8619 - lr: 1.3500e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3317 - accuracy: 0.8539 - lr: 1.3500e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3361 - accuracy: 0.8560 - lr: 1.3500e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3357 - accuracy: 0.8550 - lr: 1.3500e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3282 - accuracy: 0.8637 - lr: 1.3500e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3291 - accuracy: 0.8685 - lr: 1.3500e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3318 - accuracy: 0.8609 - lr: 1.3500e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.3325 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3255 - accuracy: 0.8598 - lr: 1.3500e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3303 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3367 - accuracy: 0.8553 - lr: 1.3500e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3256 - accuracy: 0.8623 - lr: 1.3500e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.3256 - accuracy: 0.8609 - lr: 1.3500e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3384 - accuracy: 0.8518 - lr: 1.3500e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.3327 - accuracy: 0.8529 - lr: 1.3500e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.3290 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3310 - accuracy: 0.8504 - lr: 1.3500e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3326 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.3303 - accuracy: 0.8609 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.3154 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 37ms/step\n",
      "22/22 [==============================] - 1s 37ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 9s 252ms/step - loss: 0.6177 - accuracy: 0.6879 - lr: 1.3500e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.5197 - accuracy: 0.7727 - lr: 1.3500e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.4828 - accuracy: 0.7911 - lr: 1.3500e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.4603 - accuracy: 0.7999 - lr: 1.3500e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 7s 254ms/step - loss: 0.4528 - accuracy: 0.8037 - lr: 1.3500e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.4496 - accuracy: 0.7999 - lr: 1.3500e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.4398 - accuracy: 0.8162 - lr: 1.3500e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.4304 - accuracy: 0.8180 - lr: 1.3500e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 7s 254ms/step - loss: 0.4288 - accuracy: 0.8208 - lr: 1.3500e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.4225 - accuracy: 0.8211 - lr: 1.3500e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.4199 - accuracy: 0.8204 - lr: 1.3500e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.4186 - accuracy: 0.8229 - lr: 1.3500e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.4157 - accuracy: 0.8246 - lr: 1.3500e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 7s 254ms/step - loss: 0.4115 - accuracy: 0.8264 - lr: 1.3500e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.4097 - accuracy: 0.8264 - lr: 1.3500e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.4084 - accuracy: 0.8264 - lr: 1.3500e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.4007 - accuracy: 0.8316 - lr: 1.3500e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3955 - accuracy: 0.8309 - lr: 1.3500e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3930 - accuracy: 0.8361 - lr: 1.3500e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3940 - accuracy: 0.8365 - lr: 1.3500e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3890 - accuracy: 0.8365 - lr: 1.3500e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3924 - accuracy: 0.8333 - lr: 1.3500e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3875 - accuracy: 0.8358 - lr: 1.3500e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3843 - accuracy: 0.8396 - lr: 1.3500e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3771 - accuracy: 0.8414 - lr: 1.3500e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3784 - accuracy: 0.8382 - lr: 1.3500e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3792 - accuracy: 0.8382 - lr: 1.3500e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3677 - accuracy: 0.8431 - lr: 1.3500e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3692 - accuracy: 0.8445 - lr: 1.3500e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3683 - accuracy: 0.8455 - lr: 1.3500e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3706 - accuracy: 0.8445 - lr: 1.3500e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3628 - accuracy: 0.8494 - lr: 1.3500e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3642 - accuracy: 0.8431 - lr: 1.3500e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3684 - accuracy: 0.8431 - lr: 1.3500e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3581 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3629 - accuracy: 0.8511 - lr: 1.3500e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3708 - accuracy: 0.8396 - lr: 1.3500e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3646 - accuracy: 0.8455 - lr: 1.3500e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3541 - accuracy: 0.8532 - lr: 1.3500e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3567 - accuracy: 0.8518 - lr: 1.3500e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3541 - accuracy: 0.8532 - lr: 1.3500e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 7s 254ms/step - loss: 0.3498 - accuracy: 0.8560 - lr: 1.3500e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3580 - accuracy: 0.8504 - lr: 1.3500e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3529 - accuracy: 0.8487 - lr: 1.3500e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3507 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3497 - accuracy: 0.8574 - lr: 1.3500e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3472 - accuracy: 0.8577 - lr: 1.3500e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3478 - accuracy: 0.8550 - lr: 1.3500e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3427 - accuracy: 0.8577 - lr: 1.3500e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3466 - accuracy: 0.8570 - lr: 1.3500e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3495 - accuracy: 0.8553 - lr: 1.3500e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3434 - accuracy: 0.8595 - lr: 1.3500e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3408 - accuracy: 0.8651 - lr: 1.3500e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3424 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3449 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3508 - accuracy: 0.8487 - lr: 1.3500e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3497 - accuracy: 0.8570 - lr: 1.3500e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3479 - accuracy: 0.8577 - lr: 1.3500e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3394 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3477 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3418 - accuracy: 0.8581 - lr: 1.3500e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3450 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3433 - accuracy: 0.8539 - lr: 1.3500e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3490 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3367 - accuracy: 0.8630 - lr: 1.3500e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 7s 232ms/step - loss: 0.3344 - accuracy: 0.8609 - lr: 1.3500e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3403 - accuracy: 0.8570 - lr: 1.3500e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3336 - accuracy: 0.8574 - lr: 1.3500e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3359 - accuracy: 0.8591 - lr: 1.3500e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.3351 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3386 - accuracy: 0.8602 - lr: 1.3500e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3404 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3367 - accuracy: 0.8560 - lr: 1.3500e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3417 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3332 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3325 - accuracy: 0.8640 - lr: 1.3500e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3326 - accuracy: 0.8612 - lr: 1.3500e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3346 - accuracy: 0.8602 - lr: 1.3500e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3314 - accuracy: 0.8630 - lr: 1.3500e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 7s 254ms/step - loss: 0.3381 - accuracy: 0.8588 - lr: 1.3500e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3325 - accuracy: 0.8633 - lr: 1.3500e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3368 - accuracy: 0.8626 - lr: 1.3500e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.3356 - accuracy: 0.8602 - lr: 1.3500e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3373 - accuracy: 0.8612 - lr: 1.3500e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3416 - accuracy: 0.8595 - lr: 1.3500e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.3388 - accuracy: 0.8598 - lr: 1.3500e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3331 - accuracy: 0.8598 - lr: 1.3500e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.3324 - accuracy: 0.8581 - lr: 1.3500e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3306 - accuracy: 0.8612 - lr: 1.3500e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3299 - accuracy: 0.8626 - lr: 1.3500e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.3391 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.3331 - accuracy: 0.8598 - lr: 1.3500e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3380 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.3350 - accuracy: 0.8588 - lr: 1.3500e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.3264 - accuracy: 0.8637 - lr: 1.3500e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3290 - accuracy: 0.8654 - lr: 1.3500e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.3343 - accuracy: 0.8630 - lr: 1.3500e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 7s 251ms/step - loss: 0.3271 - accuracy: 0.8647 - lr: 1.3500e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.3236 - accuracy: 0.8668 - lr: 1.3500e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3246 - accuracy: 0.8623 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.3768 - accuracy: 0.8195 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 39ms/step\n",
      "22/22 [==============================] - 1s 39ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 9s 260ms/step - loss: 0.6100 - accuracy: 0.6803 - lr: 1.3500e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.5181 - accuracy: 0.7775 - lr: 1.3500e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.4792 - accuracy: 0.7922 - lr: 1.3500e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.4616 - accuracy: 0.7988 - lr: 1.3500e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.4439 - accuracy: 0.8100 - lr: 1.3500e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.4411 - accuracy: 0.8145 - lr: 1.3500e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.4399 - accuracy: 0.8142 - lr: 1.3500e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.4404 - accuracy: 0.8128 - lr: 1.3500e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.4284 - accuracy: 0.8159 - lr: 1.3500e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.4244 - accuracy: 0.8253 - lr: 1.3500e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 0.4202 - accuracy: 0.8149 - lr: 1.3500e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.4121 - accuracy: 0.8190 - lr: 1.3500e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.4082 - accuracy: 0.8271 - lr: 1.3500e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.4030 - accuracy: 0.8330 - lr: 1.3500e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.3953 - accuracy: 0.8386 - lr: 1.3500e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.4003 - accuracy: 0.8326 - lr: 1.3500e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.3929 - accuracy: 0.8393 - lr: 1.3500e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3895 - accuracy: 0.8372 - lr: 1.3500e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.3996 - accuracy: 0.8354 - lr: 1.3500e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3919 - accuracy: 0.8386 - lr: 1.3500e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3854 - accuracy: 0.8372 - lr: 1.3500e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3847 - accuracy: 0.8424 - lr: 1.3500e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.3814 - accuracy: 0.8452 - lr: 1.3500e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3840 - accuracy: 0.8414 - lr: 1.3500e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3766 - accuracy: 0.8389 - lr: 1.3500e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 7s 259ms/step - loss: 0.3796 - accuracy: 0.8396 - lr: 1.3500e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.3782 - accuracy: 0.8375 - lr: 1.3500e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3788 - accuracy: 0.8410 - lr: 1.3500e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3735 - accuracy: 0.8466 - lr: 1.3500e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3746 - accuracy: 0.8389 - lr: 1.3500e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3727 - accuracy: 0.8427 - lr: 1.3500e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3699 - accuracy: 0.8438 - lr: 1.3500e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.3847 - accuracy: 0.8326 - lr: 1.3500e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3761 - accuracy: 0.8421 - lr: 1.3500e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3703 - accuracy: 0.8504 - lr: 1.3500e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.3704 - accuracy: 0.8452 - lr: 1.3500e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3660 - accuracy: 0.8473 - lr: 1.3500e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.3590 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3693 - accuracy: 0.8462 - lr: 1.3500e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.3631 - accuracy: 0.8459 - lr: 1.3500e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.3644 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3617 - accuracy: 0.8445 - lr: 1.3500e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3568 - accuracy: 0.8497 - lr: 1.3500e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3555 - accuracy: 0.8497 - lr: 1.3500e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 0.3566 - accuracy: 0.8473 - lr: 1.3500e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3535 - accuracy: 0.8462 - lr: 1.3500e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3587 - accuracy: 0.8452 - lr: 1.3500e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3565 - accuracy: 0.8476 - lr: 1.3500e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3522 - accuracy: 0.8508 - lr: 1.3500e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.3445 - accuracy: 0.8508 - lr: 1.3500e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3520 - accuracy: 0.8504 - lr: 1.3500e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3488 - accuracy: 0.8532 - lr: 1.3500e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3433 - accuracy: 0.8525 - lr: 1.3500e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 0.3549 - accuracy: 0.8431 - lr: 1.3500e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.3514 - accuracy: 0.8532 - lr: 1.3500e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3466 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3494 - accuracy: 0.8508 - lr: 1.3500e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 0.3504 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3665 - accuracy: 0.8438 - lr: 1.3500e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 0.3490 - accuracy: 0.8487 - lr: 1.3500e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3401 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.3368 - accuracy: 0.8529 - lr: 1.3500e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.3557 - accuracy: 0.8518 - lr: 1.3500e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 0.3467 - accuracy: 0.8570 - lr: 1.3500e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3505 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.3479 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.3419 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3427 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3450 - accuracy: 0.8539 - lr: 1.3500e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3403 - accuracy: 0.8570 - lr: 1.3500e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.3387 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3364 - accuracy: 0.8588 - lr: 1.3500e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3376 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3544 - accuracy: 0.8459 - lr: 1.3500e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3397 - accuracy: 0.8553 - lr: 1.3500e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3405 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 0.3528 - accuracy: 0.8539 - lr: 1.3500e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.3473 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3393 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3575 - accuracy: 0.8462 - lr: 1.3500e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3476 - accuracy: 0.8532 - lr: 1.3500e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3379 - accuracy: 0.8529 - lr: 1.3500e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3382 - accuracy: 0.8556 - lr: 1.3500e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3414 - accuracy: 0.8581 - lr: 1.3500e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3429 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.3409 - accuracy: 0.8560 - lr: 1.3500e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3331 - accuracy: 0.8591 - lr: 1.3500e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 7s 254ms/step - loss: 0.3413 - accuracy: 0.8612 - lr: 1.3500e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3392 - accuracy: 0.8574 - lr: 1.3500e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.3338 - accuracy: 0.8584 - lr: 1.3500e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.3449 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 0.3297 - accuracy: 0.8605 - lr: 1.3500e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3353 - accuracy: 0.8574 - lr: 1.3500e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 0.3395 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3380 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 7s 259ms/step - loss: 0.3301 - accuracy: 0.8630 - lr: 1.3500e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3338 - accuracy: 0.8546 - lr: 1.3500e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 7s 254ms/step - loss: 0.3311 - accuracy: 0.8616 - lr: 1.3500e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3354 - accuracy: 0.8581 - lr: 1.3500e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.3367 - accuracy: 0.8529 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 37ms/step - loss: 0.3386 - accuracy: 0.8567 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 37ms/step\n",
      "22/22 [==============================] - 1s 37ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 9s 262ms/step - loss: 0.6395 - accuracy: 0.6715 - lr: 1.3500e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.5184 - accuracy: 0.7706 - lr: 1.3500e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.4672 - accuracy: 0.8033 - lr: 1.3500e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.4560 - accuracy: 0.8044 - lr: 1.3500e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.4485 - accuracy: 0.8145 - lr: 1.3500e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.4410 - accuracy: 0.8093 - lr: 1.3500e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.4285 - accuracy: 0.8211 - lr: 1.3500e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.4283 - accuracy: 0.8169 - lr: 1.3500e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.4226 - accuracy: 0.8229 - lr: 1.3500e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.4191 - accuracy: 0.8232 - lr: 1.3500e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.4144 - accuracy: 0.8260 - lr: 1.3500e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.4138 - accuracy: 0.8260 - lr: 1.3500e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.4160 - accuracy: 0.8201 - lr: 1.3500e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.4126 - accuracy: 0.8267 - lr: 1.3500e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.4047 - accuracy: 0.8281 - lr: 1.3500e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.4020 - accuracy: 0.8302 - lr: 1.3500e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.4045 - accuracy: 0.8253 - lr: 1.3500e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.3990 - accuracy: 0.8309 - lr: 1.3500e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3954 - accuracy: 0.8358 - lr: 1.3500e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3886 - accuracy: 0.8382 - lr: 1.3500e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3898 - accuracy: 0.8365 - lr: 1.3500e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.3899 - accuracy: 0.8319 - lr: 1.3500e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3909 - accuracy: 0.8326 - lr: 1.3500e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3872 - accuracy: 0.8375 - lr: 1.3500e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3876 - accuracy: 0.8309 - lr: 1.3500e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3852 - accuracy: 0.8285 - lr: 1.3500e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3891 - accuracy: 0.8337 - lr: 1.3500e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3862 - accuracy: 0.8382 - lr: 1.3500e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3814 - accuracy: 0.8382 - lr: 1.3500e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 8s 272ms/step - loss: 0.3787 - accuracy: 0.8414 - lr: 1.3500e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3786 - accuracy: 0.8410 - lr: 1.3500e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 8s 272ms/step - loss: 0.3739 - accuracy: 0.8410 - lr: 1.3500e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3779 - accuracy: 0.8421 - lr: 1.3500e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 8s 273ms/step - loss: 0.3737 - accuracy: 0.8403 - lr: 1.3500e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3689 - accuracy: 0.8462 - lr: 1.3500e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3730 - accuracy: 0.8487 - lr: 1.3500e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3719 - accuracy: 0.8466 - lr: 1.3500e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3724 - accuracy: 0.8403 - lr: 1.3500e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3697 - accuracy: 0.8407 - lr: 1.3500e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.3655 - accuracy: 0.8462 - lr: 1.3500e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.3651 - accuracy: 0.8421 - lr: 1.3500e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3632 - accuracy: 0.8441 - lr: 1.3500e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3618 - accuracy: 0.8508 - lr: 1.3500e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3620 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3722 - accuracy: 0.8427 - lr: 1.3500e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3653 - accuracy: 0.8455 - lr: 1.3500e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3662 - accuracy: 0.8469 - lr: 1.3500e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3602 - accuracy: 0.8445 - lr: 1.3500e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3589 - accuracy: 0.8508 - lr: 1.3500e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3689 - accuracy: 0.8427 - lr: 1.3500e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3616 - accuracy: 0.8466 - lr: 1.3500e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3584 - accuracy: 0.8469 - lr: 1.3500e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3619 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.3595 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3551 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3524 - accuracy: 0.8508 - lr: 1.3500e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3555 - accuracy: 0.8525 - lr: 1.3500e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3546 - accuracy: 0.8476 - lr: 1.3500e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.3530 - accuracy: 0.8476 - lr: 1.3500e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.3570 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3534 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 8s 262ms/step - loss: 0.3544 - accuracy: 0.8546 - lr: 1.3500e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3500 - accuracy: 0.8518 - lr: 1.3500e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3513 - accuracy: 0.8487 - lr: 1.3500e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 8s 274ms/step - loss: 0.3464 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.3507 - accuracy: 0.8532 - lr: 1.3500e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3474 - accuracy: 0.8490 - lr: 1.3500e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3463 - accuracy: 0.8480 - lr: 1.3500e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 8s 267ms/step - loss: 0.3649 - accuracy: 0.8414 - lr: 1.3500e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3543 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.3519 - accuracy: 0.8466 - lr: 1.3500e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3503 - accuracy: 0.8508 - lr: 1.3500e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.3498 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3494 - accuracy: 0.8476 - lr: 1.3500e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 8s 272ms/step - loss: 0.3509 - accuracy: 0.8483 - lr: 1.3500e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3490 - accuracy: 0.8466 - lr: 1.3500e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3454 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3476 - accuracy: 0.8494 - lr: 1.3500e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3479 - accuracy: 0.8504 - lr: 1.3500e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.3448 - accuracy: 0.8529 - lr: 1.3500e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3403 - accuracy: 0.8563 - lr: 1.3500e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3416 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3414 - accuracy: 0.8518 - lr: 1.3500e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3410 - accuracy: 0.8518 - lr: 1.3500e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3457 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3449 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3375 - accuracy: 0.8546 - lr: 1.3500e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3390 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3401 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3449 - accuracy: 0.8522 - lr: 1.3500e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 0.3382 - accuracy: 0.8518 - lr: 1.3500e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.3431 - accuracy: 0.8581 - lr: 1.3500e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3468 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.3447 - accuracy: 0.8515 - lr: 1.3500e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 0.3406 - accuracy: 0.8570 - lr: 1.3500e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 0.3421 - accuracy: 0.8497 - lr: 1.3500e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3418 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 0.3409 - accuracy: 0.8501 - lr: 1.3500e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 0.3343 - accuracy: 0.8536 - lr: 1.3500e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.3380 - accuracy: 0.8543 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.2920 - accuracy: 0.8782 - lr: 1.3500e-04\n",
      "22/22 [==============================] - 1s 38ms/step\n",
      "22/22 [==============================] - 1s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "tprs=[]\n",
    "mean_fpr=np.linspace(0,1,100)\n",
    "auck=[0,0,0,0,0]\n",
    "Recalls=[]\n",
    "F1score=[]\n",
    "\n",
    "for i in range(5):\n",
    "    if i==0:\n",
    "        x_train, y_train = x_train0,y_train0\n",
    "        x_test, y_test = x_test0,y_test0\n",
    "        model.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model.predict(x_test))\n",
    "        y_pred=model.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==1:\n",
    "        x_train, y_train = x_train1,y_train1\n",
    "        x_test, y_test = x_test1,y_test1\n",
    "        model2.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model2.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model2.predict(x_test))\n",
    "        y_pred=model2.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==2:\n",
    "        x_train, y_train = x_train2,y_train2\n",
    "        x_test, y_test = x_test2,y_test2\n",
    "        model3.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model3.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model3.predict(x_test))\n",
    "        y_pred=model3.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==3:\n",
    "        x_train, y_train = x_train3,y_train3\n",
    "        x_test, y_test = x_test3,y_test3\n",
    "        model4.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model4.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model4.predict(x_test))\n",
    "        y_pred=model4.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    else:\n",
    "        x_train, y_train = x_train4,y_train4\n",
    "        x_test, y_test = x_test4,y_test4\n",
    "        model5.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model5.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model5.predict(x_test))\n",
    "        y_pred=model5.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    auck[i] = auc(fpr, tpr)\n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "scores=np.array(scores)\n",
    "interval = stats.t.interval(0.95, scores.shape[0] - 1, scores.mean(), scores.std() / np.sqrt(scores.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc5b3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence interval：(0.7848264352921821, 0.8850875718947075)\n",
      "scores: 0.8349570035934448\n",
      "AUC: 0.9369123325005677\n"
     ]
    }
   ],
   "source": [
    "print(\"confidence interval：{}\".format(interval))\n",
    "print('scores:',np.mean(scores))\n",
    "print('AUC:',np.mean(auck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53c4f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalls: 0.9449579831932773\n",
      "F1score: 0.8861403827927059\n"
     ]
    }
   ],
   "source": [
    "print('Recalls:',np.mean(Recalls))\n",
    "print('F1score:',np.mean(F1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8052051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9369123325005677\n",
      "AUC confidence interval: (0.9293386818539385, 0.9444859831471969)\n"
     ]
    }
   ],
   "source": [
    "print('AUC:',np.mean(auck))\n",
    "conf = sms.DescrStatsW(auck).tconfint_mean(0.05)\n",
    "print('AUC confidence interval:',conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b671583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2119f6b2800>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='r',alpha=0.1)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "mean_tpr=np.mean(tprs,axis=0)\n",
    "mean_tpr[-1]=1.0\n",
    "std_auc=np.std(tprs,axis=0)\n",
    "plt.plot(mean_fpr,mean_tpr,color='b',label = u'AUC=%.3f' % (sum(auck)/5),lw=2,alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by Anaconda, Inc. | (main, Mar  8 2023, 10:42:25) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
